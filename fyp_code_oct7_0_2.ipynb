{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4cmvBg/uVTVXvsPP/bQJd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SrivardhanS/Speech_GNN_FYP/blob/main/fyp_code_oct7_0_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw-sNX50DSLa",
        "outputId": "f07c5de2-4250-4f92-a9a1-5df9520ef45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.9/542.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.6/792.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'asvpoof-2019-dataset' dataset.\n",
            "19:03:23 [INFO] Dataset path: /kaggle/input/asvpoof-2019-dataset\n",
            "19:03:23 [INFO] Train protocol sample:\n",
            "    utt_id    speaker_id system_id attack_id     label\n",
            "0  LA_0079  LA_T_1138215         -         -  bonafide\n",
            "1  LA_0079  LA_T_1271820         -         -  bonafide\n",
            "2  LA_0079  LA_T_1272637         -         -  bonafide\n",
            "3  LA_0079  LA_T_1276960         -         -  bonafide\n",
            "4  LA_0079  LA_T_1341447         -         -  bonafide\n",
            "19:03:23 [INFO] Dev protocol loaded: 24844 samples\n",
            "19:03:23 [INFO] Eval protocol loaded: 71237 samples\n",
            "19:03:23 [INFO] Using device: cpu\n",
            "19:03:23 [INFO] Building training graphs...\n",
            "19:03:46 [INFO] Building dev graphs...\n",
            "19:03:47 [INFO] Building eval graphs...\n",
            "19:03:58 [INFO] Epoch 1 | Batch 20/100 | cls_loss=0.0000 comp_loss=0.0445\n",
            "19:04:07 [INFO] Epoch 1 | Batch 40/100 | cls_loss=0.0000 comp_loss=0.0443\n",
            "19:04:16 [INFO] Epoch 1 | Batch 60/100 | cls_loss=0.0000 comp_loss=0.0445\n",
            "19:04:24 [INFO] Epoch 1 | Batch 80/100 | cls_loss=0.0000 comp_loss=0.0445\n",
            "19:04:33 [INFO] Epoch 1 | Batch 100/100 | cls_loss=0.0000 comp_loss=0.0445\n",
            "19:04:33 [INFO] Epoch 1: cls_loss=1.2793 | comp_loss=0.0444\n",
            "19:04:49 [INFO] Epoch 1 Dev: acc=1.0000, f1=1.0000, auc=nan\n",
            "19:04:49 [INFO] ✅ Best model saved (Dev F1: 1.0000)\n",
            "19:04:58 [INFO] Epoch 2 | Batch 20/100 | cls_loss=0.0000 comp_loss=0.0449\n",
            "19:05:07 [INFO] Epoch 2 | Batch 40/100 | cls_loss=0.0000 comp_loss=0.0443\n",
            "19:05:14 [INFO] Epoch 2 | Batch 60/100 | cls_loss=0.0000 comp_loss=0.0447\n",
            "19:05:25 [INFO] Epoch 2 | Batch 80/100 | cls_loss=0.0000 comp_loss=0.0442\n",
            "19:05:33 [INFO] Epoch 2 | Batch 100/100 | cls_loss=0.0000 comp_loss=0.0443\n",
            "19:05:33 [INFO] Epoch 2: cls_loss=0.0000 | comp_loss=0.0444\n",
            "19:05:48 [INFO] Epoch 2 Dev: acc=1.0000, f1=1.0000, auc=nan\n",
            "19:05:57 [INFO] Epoch 3 | Batch 20/100 | cls_loss=0.0000 comp_loss=0.0444\n",
            "19:06:05 [INFO] Epoch 3 | Batch 40/100 | cls_loss=0.0000 comp_loss=0.0442\n",
            "19:06:14 [INFO] Epoch 3 | Batch 60/100 | cls_loss=0.0000 comp_loss=0.0444\n",
            "19:06:24 [INFO] Epoch 3 | Batch 80/100 | cls_loss=0.0000 comp_loss=0.0444\n",
            "19:06:33 [INFO] Epoch 3 | Batch 100/100 | cls_loss=0.0000 comp_loss=0.0442\n",
            "19:06:33 [INFO] Epoch 3: cls_loss=0.0000 | comp_loss=0.0444\n",
            "19:06:48 [INFO] Epoch 3 Dev: acc=1.0000, f1=1.0000, auc=nan\n",
            "19:06:59 [INFO] Epoch 4 | Batch 20/100 | cls_loss=0.0000 comp_loss=0.0442\n",
            "19:07:09 [INFO] Epoch 4 | Batch 40/100 | cls_loss=0.0000 comp_loss=0.0441\n",
            "19:07:19 [INFO] Epoch 4 | Batch 60/100 | cls_loss=0.0000 comp_loss=0.0442\n",
            "19:07:31 [INFO] Epoch 4 | Batch 80/100 | cls_loss=0.0000 comp_loss=0.0443\n",
            "19:07:39 [INFO] Epoch 4 | Batch 100/100 | cls_loss=0.0000 comp_loss=0.0444\n",
            "19:07:39 [INFO] Epoch 4: cls_loss=0.0000 | comp_loss=0.0444\n",
            "19:07:55 [INFO] Epoch 4 Dev: acc=1.0000, f1=1.0000, auc=nan\n",
            "19:08:03 [INFO] Epoch 5 | Batch 20/100 | cls_loss=0.0000 comp_loss=0.0445\n",
            "19:08:12 [INFO] Epoch 5 | Batch 40/100 | cls_loss=0.0000 comp_loss=0.0443\n",
            "19:08:22 [INFO] Epoch 5 | Batch 60/100 | cls_loss=0.0000 comp_loss=0.0441\n",
            "19:08:29 [INFO] Epoch 5 | Batch 80/100 | cls_loss=0.0000 comp_loss=0.0442\n",
            "19:08:38 [INFO] Epoch 5 | Batch 100/100 | cls_loss=0.0000 comp_loss=0.0444\n",
            "19:08:38 [INFO] Epoch 5: cls_loss=0.0000 | comp_loss=0.0444\n",
            "19:08:53 [INFO] Epoch 5 Dev: acc=1.0000, f1=1.0000, auc=nan\n",
            "19:08:53 [INFO] \n",
            "============================================================\n",
            "19:08:53 [INFO] FINAL EVALUATION ON TEST SET\n",
            "19:08:53 [INFO] ============================================================\n",
            "19:08:53 [INFO] Loaded best model from epoch 1\n",
            "19:08:53 [INFO] \n",
            "--- Training Set Results ---\n",
            "19:09:17 [INFO] Accuracy : 1.0000\n",
            "19:09:17 [INFO] Precision: 1.0000\n",
            "19:09:17 [INFO] Recall   : 1.0000\n",
            "19:09:17 [INFO] F1-score : 1.0000\n",
            "19:09:17 [INFO] AUC      : nan\n",
            "19:09:17 [INFO] \n",
            "Confusion Matrix:\n",
            "[[100]]\n",
            "19:09:17 [INFO] Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     1.0000    1.0000    1.0000       100\n",
            "\n",
            "    accuracy                         1.0000       100\n",
            "   macro avg     1.0000    1.0000    1.0000       100\n",
            "weighted avg     1.0000    1.0000    1.0000       100\n",
            "\n",
            "19:09:17 [INFO] \n",
            "--- Dev Set Results ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19:09:32 [INFO] Accuracy : 1.0000\n",
            "19:09:32 [INFO] Precision: 1.0000\n",
            "19:09:32 [INFO] Recall   : 1.0000\n",
            "19:09:32 [INFO] F1-score : 1.0000\n",
            "19:09:32 [INFO] AUC      : nan\n",
            "19:09:32 [INFO] \n",
            "Confusion Matrix:\n",
            "[[50]]\n",
            "19:09:32 [INFO] Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     1.0000    1.0000    1.0000        50\n",
            "\n",
            "    accuracy                         1.0000        50\n",
            "   macro avg     1.0000    1.0000    1.0000        50\n",
            "weighted avg     1.0000    1.0000    1.0000        50\n",
            "\n",
            "19:09:32 [INFO] \n",
            "--- Test Set Results ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19:09:53 [INFO] Accuracy : 0.1400\n",
            "19:09:53 [INFO] Precision: 0.1400\n",
            "19:09:53 [INFO] Recall   : 1.0000\n",
            "19:09:53 [INFO] F1-score : 0.2456\n",
            "19:09:53 [INFO] AUC      : 0.5\n",
            "19:09:53 [INFO] \n",
            "Confusion Matrix:\n",
            "[[ 0 86]\n",
            " [ 0 14]]\n",
            "19:09:53 [INFO] Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000        86\n",
            "           1     0.1400    1.0000    0.2456        14\n",
            "\n",
            "    accuracy                         0.1400       100\n",
            "   macro avg     0.0700    0.5000    0.1228       100\n",
            "weighted avg     0.0196    0.1400    0.0344       100\n",
            "\n",
            "19:09:53 [INFO] \n",
            "============================================================\n",
            "19:09:53 [INFO] EVALUATION COMPLETE\n",
            "19:09:53 [INFO] ============================================================\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# Full: Compression + GCN training for ASVspoof2019 LA WITH EVALUATION\n",
        "# ======================\n",
        "\n",
        "# Install dependencies first\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install -q torch-spline-conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install -q torch-geometric\n",
        "!pip install -q kaggle librosa\n",
        "\n",
        "import os, sys, logging, random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, confusion_matrix,\n",
        "                             classification_report)\n",
        "\n",
        "# Logging setup (Colab-friendly)\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    datefmt=\"%H:%M:%S\",\n",
        "    handlers=[logging.StreamHandler(sys.stdout)],\n",
        "    force=True\n",
        ")\n",
        "logger = logging.getLogger(\"asvspoof-compress-train\")\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# Dataset / Protocols\n",
        "# ----------------------\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"awsaf49/asvpoof-2019-dataset\")\n",
        "logger.info(f\"Dataset path: {path}\")\n",
        "\n",
        "dataset_path = os.path.join(path, \"LA\", \"LA\")\n",
        "proto_dir = os.path.join(dataset_path, \"ASVspoof2019_LA_cm_protocols\")\n",
        "train_proto = os.path.join(proto_dir, \"ASVspoof2019.LA.cm.train.trn.txt\")\n",
        "dev_proto = os.path.join(proto_dir, \"ASVspoof2019.LA.cm.dev.trl.txt\")\n",
        "eval_proto = os.path.join(proto_dir, \"ASVspoof2019.LA.cm.eval.trl.txt\")\n",
        "\n",
        "train_audio_dir = os.path.join(dataset_path, \"ASVspoof2019_LA_train\", \"flac\")\n",
        "dev_audio_dir   = os.path.join(dataset_path, \"ASVspoof2019_LA_dev\", \"flac\")\n",
        "eval_audio_dir  = os.path.join(dataset_path, \"ASVspoof2019_LA_eval\", \"flac\")\n",
        "\n",
        "# Load protocols\n",
        "protocol_df = pd.read_csv(train_proto, sep=\" \", header=None)\n",
        "protocol_df.columns = [\"utt_id\", \"speaker_id\", \"system_id\", \"attack_id\", \"label\"]\n",
        "logger.info(f\"Train protocol sample:\\n{protocol_df.head()}\")\n",
        "\n",
        "dev_df = pd.read_csv(dev_proto, sep=\" \", header=None)\n",
        "dev_df.columns = [\"utt_id\", \"speaker_id\", \"system_id\", \"attack_id\", \"label\"]\n",
        "logger.info(f\"Dev protocol loaded: {len(dev_df)} samples\")\n",
        "\n",
        "eval_df = pd.read_csv(eval_proto, sep=\" \", header=None)\n",
        "eval_df.columns = [\"utt_id\", \"speaker_id\", \"system_id\", \"attack_id\", \"label\"]\n",
        "logger.info(f\"Eval protocol loaded: {len(eval_df)} samples\")\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# audio -> temporal graph\n",
        "# ----------------------\n",
        "def audio_to_graph(file_path, sr=16000, n_mfcc=13, pool_size=4):\n",
        "    # load\n",
        "    y, _ = librosa.load(file_path, sr=sr)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    # pool frames\n",
        "    T = mfcc.shape[1] // pool_size\n",
        "    if T < 2:\n",
        "        # pad/truncate guards\n",
        "        mfcc = np.pad(mfcc, ((0,0),(0, pool_size*2 - mfcc.shape[1])), mode='wrap')\n",
        "        T = mfcc.shape[1] // pool_size\n",
        "    pooled = np.stack([ np.mean(mfcc[:, i*pool_size:(i+1)*pool_size], axis=1) for i in range(T) ])\n",
        "\n",
        "    x = torch.tensor(pooled, dtype=torch.float)        # [nodes, feat]\n",
        "    if x.size(0) < 2:\n",
        "        # ensure at least 2 nodes (avoid zero-edge)\n",
        "        x = torch.cat([x, x], dim=0)\n",
        "    edge_index = torch.tensor([[i,i+1] for i in range(x.size(0)-1)], dtype=torch.long).T\n",
        "    return Data(x=x, edge_index=edge_index)\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# DifferentiableGraphCompressor\n",
        "# ----------------------\n",
        "class DifferentiableGraphCompressor(nn.Module):\n",
        "    def __init__(self, feature_dim, tau_T=1.0, lambda_id=1.0, lambda_comp=0.1):\n",
        "        super().__init__()\n",
        "        self.a_raw = nn.Parameter(torch.tensor(0.0))\n",
        "        self.tau_T = tau_T\n",
        "        self.lambda_id = lambda_id\n",
        "        self.lambda_comp = lambda_comp\n",
        "        self.speaker_embedding = nn.Sequential(\n",
        "            nn.Linear(feature_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32)\n",
        "        )\n",
        "\n",
        "    def get_alpha(self):\n",
        "        return torch.sigmoid(self.a_raw)\n",
        "\n",
        "    def node_similarity(self, x_u, x_v):\n",
        "        return F.cosine_similarity(x_u.unsqueeze(0), x_v.unsqueeze(0), dim=1)\n",
        "\n",
        "    def neighborhood_similarity(self, x, edge_index, u, v):\n",
        "        def get_neighbors(node):\n",
        "            mask = (edge_index[0] == node)\n",
        "            if mask.any():\n",
        "                return edge_index[1][mask]\n",
        "            else:\n",
        "                return torch.tensor([], dtype=torch.long, device=x.device)\n",
        "\n",
        "        neighbors_u = get_neighbors(u)\n",
        "        neighbors_v = get_neighbors(v)\n",
        "        if neighbors_u.numel() == 0 or neighbors_v.numel() == 0:\n",
        "            return torch.tensor(0.0, device=x.device)\n",
        "        m_u = x[neighbors_u].mean(dim=0)\n",
        "        m_v = x[neighbors_v].mean(dim=0)\n",
        "        return F.cosine_similarity(m_u.unsqueeze(0), m_v.unsqueeze(0), dim=1)\n",
        "\n",
        "    def combined_similarity(self, x, edge_index, u, v):\n",
        "        alpha = self.get_alpha()\n",
        "        sim_x = self.node_similarity(x[u], x[v])\n",
        "        sim_m = self.neighborhood_similarity(x, edge_index, u, v)\n",
        "        return alpha * sim_x + (1 - alpha) * sim_m\n",
        "\n",
        "    def compute_adaptive_thresholds(self, similarities):\n",
        "        tau_1_bar = torch.quantile(similarities, 0.75)\n",
        "        tau_2_bar = torch.quantile(similarities, 0.60)\n",
        "        return tau_1_bar, tau_2_bar\n",
        "\n",
        "    def compute_merge_probabilities(self, x, edge_index, window_size=10):\n",
        "        num_nodes = x.size(0)\n",
        "        merge_probs = torch.zeros(num_nodes, device=x.device)\n",
        "        all_similarities = []\n",
        "\n",
        "        for t in range(1, num_nodes - 1):\n",
        "            for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                if t + k >= num_nodes - 1:\n",
        "                    continue\n",
        "                try:\n",
        "                    s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                    s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                    s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                    all_similarities.extend([s1, s2, s3])\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "        if len(all_similarities) == 0:\n",
        "            return merge_probs\n",
        "\n",
        "        similarities_tensor = torch.stack(all_similarities).view(-1)\n",
        "        tau_1_bar, tau_2_bar = self.compute_adaptive_thresholds(similarities_tensor)\n",
        "\n",
        "        for t in range(1, num_nodes - 1):\n",
        "            max_prob = 0.0\n",
        "            for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                if t + k >= num_nodes - 1:\n",
        "                    continue\n",
        "                try:\n",
        "                    s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                    s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                    s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                    gate1 = torch.sigmoid((s1 - tau_1_bar) / self.tau_T)\n",
        "                    gate2 = torch.sigmoid((s2 - tau_2_bar) / self.tau_T)\n",
        "                    gate3 = torch.sigmoid((s3 - tau_2_bar) / self.tau_T)\n",
        "                    prob = gate1 * gate2 * gate3\n",
        "                    max_prob = max(max_prob, prob.item())\n",
        "                except Exception:\n",
        "                    continue\n",
        "            merge_probs[t] = max_prob\n",
        "\n",
        "        return merge_probs\n",
        "\n",
        "    def differentiable_compression(self, x, edge_index):\n",
        "        merge_probs = self.compute_merge_probabilities(x, edge_index)\n",
        "        x_compressed = x.clone()\n",
        "        num_nodes = x.size(0)\n",
        "        for t in range(1, num_nodes - 1):\n",
        "            if merge_probs[t] > 0:\n",
        "                best_k = 1\n",
        "                best_sim = -1\n",
        "                for k in range(1, min(10, num_nodes - t)):\n",
        "                    if t + k >= num_nodes: break\n",
        "                    try:\n",
        "                        sim = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                        if sim > best_sim:\n",
        "                            best_sim = sim\n",
        "                            best_k = k\n",
        "                    except Exception:\n",
        "                        continue\n",
        "                if t + best_k < num_nodes:\n",
        "                    p = merge_probs[t]\n",
        "                    interpolated = (x[t] + x[t + best_k]) / 2\n",
        "                    x_compressed[t] = (1 - p) * x[t] + p * interpolated\n",
        "        return x_compressed, merge_probs\n",
        "\n",
        "    def speaker_identity_loss(self, x_original, x_compressed):\n",
        "        g_original = self.speaker_embedding(x_original.mean(dim=0))\n",
        "        g_compressed = self.speaker_embedding(x_compressed.mean(dim=0))\n",
        "        cos_sim = F.cosine_similarity(g_original.unsqueeze(0), g_compressed.unsqueeze(0))\n",
        "        return 1 - cos_sim\n",
        "\n",
        "    def compression_loss(self, merge_probs):\n",
        "        return (1 - merge_probs).mean()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x_compressed, merge_probs = self.differentiable_compression(x, edge_index)\n",
        "        L_id = self.speaker_identity_loss(x, x_compressed)\n",
        "        L_comp = self.compression_loss(merge_probs)\n",
        "        total_loss = self.lambda_id * L_id + self.lambda_comp * L_comp\n",
        "        return {\n",
        "            'compressed_features': x_compressed,\n",
        "            'merge_probs': merge_probs,\n",
        "            'loss': total_loss,\n",
        "            'loss_id': L_id,\n",
        "            'loss_comp': L_comp,\n",
        "            'alpha': self.get_alpha()\n",
        "        }\n",
        "\n",
        "    def hard_compression_inference(self, x, edge_index, window_size=10):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            alpha = self.get_alpha().item()\n",
        "            num_nodes = x.size(0)\n",
        "            to_remove = set()\n",
        "            all_similarities = []\n",
        "            for t in range(1, num_nodes - 1):\n",
        "                for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                    if t + k >= num_nodes - 1: continue\n",
        "                    try:\n",
        "                        s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                        s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                        s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                        all_similarities.extend([s1, s2, s3])\n",
        "                    except Exception:\n",
        "                        continue\n",
        "            if all_similarities:\n",
        "                similarities_tensor = torch.stack(all_similarities).view(-1)\n",
        "                tau_1_hat, tau_2_hat = self.compute_adaptive_thresholds(similarities_tensor)\n",
        "                for t in range(1, num_nodes - 1):\n",
        "                    if t in to_remove: continue\n",
        "                    for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                        if t + k >= num_nodes - 1 or any(n in to_remove for n in [t, t+k, t-1, t+k-1, t+1, t+k+1]):\n",
        "                            continue\n",
        "                        try:\n",
        "                            s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                            s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                            s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                            if s1 >= tau_1_hat and s2 >= tau_2_hat and s3 >= tau_2_hat:\n",
        "                                to_remove.add(t)\n",
        "                                break\n",
        "                        except Exception:\n",
        "                            continue\n",
        "            remaining_indices = [i for i in range(num_nodes) if i not in to_remove]\n",
        "            x_new = x[remaining_indices]\n",
        "            index_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(remaining_indices)}\n",
        "            new_edges = []\n",
        "            for i in range(edge_index.size(1)):\n",
        "                src, dst = edge_index[0, i].item(), edge_index[1, i].item()\n",
        "                if src not in to_remove and dst not in to_remove:\n",
        "                    new_edges.append([index_mapping[src], index_mapping[dst]])\n",
        "            if new_edges:\n",
        "                edge_index_new = torch.tensor(new_edges, dtype=torch.long).T\n",
        "            else:\n",
        "                edge_index_new = torch.empty((2, 0), dtype=torch.long)\n",
        "            compressed_data = Data(x=x_new, edge_index=edge_index_new)\n",
        "            return compressed_data, to_remove, alpha\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# GCN classifier\n",
        "# ----------------------\n",
        "class GCNClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.fc = nn.Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return torch.sigmoid(self.fc(x)).view(-1)\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# Build lists of Data (graphs)\n",
        "# ----------------------\n",
        "def build_graph_list(df, audio_dir, limit=None, n_mfcc=13, pool_size=4):\n",
        "    graphs = []\n",
        "    rows = df.reset_index(drop=True)\n",
        "    if limit is not None:\n",
        "        rows = rows.iloc[:limit]\n",
        "    for i, row in rows.iterrows():\n",
        "        utt = row['speaker_id']\n",
        "        file_path = os.path.join(audio_dir, f\"{utt}.flac\")\n",
        "        if not os.path.isfile(file_path):\n",
        "            logger.warning(f\"Missing file {file_path}, skipping\")\n",
        "            continue\n",
        "        g = audio_to_graph(file_path, n_mfcc=n_mfcc, pool_size=pool_size)\n",
        "        g.y = torch.tensor(1 if row['label']=='bonafide' else 0, dtype=torch.float)\n",
        "        graphs.append(g)\n",
        "    return graphs\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# Training + evaluation helpers\n",
        "# ----------------------\n",
        "def train_epoch(compressor, classifier, loader, optimizer, criterion, device, epoch, lambda_comp_loss):\n",
        "    classifier.train()\n",
        "    compressor.train()\n",
        "    total_cls_loss = 0.0\n",
        "    total_comp_loss = 0.0\n",
        "    n = 0\n",
        "    for batch_idx, batch in enumerate(loader):\n",
        "        batch = batch.to(device)\n",
        "        x = batch.x\n",
        "        edge_index = batch.edge_index\n",
        "\n",
        "        # Run compressor (differentiable)\n",
        "        comp_res = compressor(x, edge_index)\n",
        "        x_compressed = comp_res['compressed_features']\n",
        "        comp_loss = comp_res['loss']\n",
        "\n",
        "        # Replace features in a new Data object and classify\n",
        "        compressed_data = Data(x=x_compressed, edge_index=edge_index, y=batch.y,\n",
        "                              batch=torch.zeros(x_compressed.size(0), dtype=torch.long, device=device))\n",
        "        compressed_data = compressed_data.to(device)\n",
        "\n",
        "        pred = classifier(compressed_data)\n",
        "        cls_loss = criterion(pred, batch.y)\n",
        "\n",
        "        loss = cls_loss + lambda_comp_loss * comp_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_cls_loss += cls_loss.item()\n",
        "        total_comp_loss += comp_loss.item()\n",
        "        n += 1\n",
        "\n",
        "        if (batch_idx + 1) % 20 == 0:\n",
        "            logger.info(f\"Epoch {epoch} | Batch {batch_idx+1}/{len(loader)} | cls_loss={cls_loss.item():.4f} comp_loss={comp_loss.item():.4f}\")\n",
        "\n",
        "    return total_cls_loss / n, total_comp_loss / n\n",
        "\n",
        "\n",
        "def evaluate_with_hard_compression(compressor, classifier, loader, device):\n",
        "    classifier.eval()\n",
        "    compressor.eval()\n",
        "    y_true, y_pred, y_prob = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            # Hard compression inference\n",
        "            compressed_data, removed, alpha = compressor.hard_compression_inference(batch.x, batch.edge_index)\n",
        "            # attach label and batch vector\n",
        "            compressed_data.y = batch.y.cpu()\n",
        "            compressed_data.batch = torch.zeros(compressed_data.x.size(0), dtype=torch.long)\n",
        "            compressed_data = compressed_data.to(device)\n",
        "\n",
        "            prob = classifier(compressed_data)\n",
        "            pred = (prob >= 0.5).long()\n",
        "            y_true.append(int(batch.y.cpu().item()))\n",
        "            y_pred.append(int(pred.cpu().item()))\n",
        "            y_prob.append(float(prob.cpu().item()))\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_true, y_prob) if len(set(y_true)) > 1 else float('nan')\n",
        "    return {\"acc\":acc, \"prec\":prec, \"rec\":rec, \"f1\":f1, \"auc\":auc,\n",
        "            \"y_true\": y_true, \"y_pred\": y_pred, \"y_prob\": y_prob}\n",
        "\n",
        "\n",
        "# ======================\n",
        "# Run compression + GCN training\n",
        "# ======================\n",
        "save_path = \"/content/gcn_compressed_asvspoof.pth\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger.info(f\"Using device: {device}\")\n",
        "\n",
        "# Build datasets\n",
        "logger.info(\"Building training graphs...\")\n",
        "train_graphs = build_graph_list(protocol_df, train_audio_dir, limit=100)  # Increase limit as needed\n",
        "train_loader = DataLoader(train_graphs, batch_size=1, shuffle=True)\n",
        "\n",
        "logger.info(\"Building dev graphs...\")\n",
        "dev_graphs = build_graph_list(dev_df, dev_audio_dir, limit=50)  # Use dev set for validation\n",
        "dev_loader = DataLoader(dev_graphs, batch_size=1, shuffle=False)\n",
        "\n",
        "logger.info(\"Building eval graphs...\")\n",
        "eval_graphs = build_graph_list(eval_df, eval_audio_dir, limit=100)  # Eval/test set\n",
        "eval_loader = DataLoader(eval_graphs, batch_size=1, shuffle=False)\n",
        "\n",
        "# Initialize models\n",
        "feature_dim = 13\n",
        "compressor = DifferentiableGraphCompressor(feature_dim, tau_T=1.0, lambda_id=1.0, lambda_comp=0.05).to(device)\n",
        "classifier = GCNClassifier(in_channels=feature_dim, hidden_channels=32).to(device)\n",
        "\n",
        "# Training setup\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(\n",
        "    list(compressor.parameters()) + list(classifier.parameters()), lr=1e-3\n",
        ")\n",
        "lambda_comp_loss = 0.1\n",
        "epochs = 5  # increase later when GPU runtime allows\n",
        "\n",
        "# Train\n",
        "best_dev_f1 = 0.0\n",
        "for epoch in range(1, epochs + 1):\n",
        "    cls_loss, comp_loss = train_epoch(\n",
        "        compressor, classifier, train_loader, optimizer, criterion, device, epoch, lambda_comp_loss\n",
        "    )\n",
        "    logger.info(f\"Epoch {epoch}: cls_loss={cls_loss:.4f} | comp_loss={comp_loss:.4f}\")\n",
        "\n",
        "    # Evaluate on dev set after each epoch\n",
        "    dev_metrics = evaluate_with_hard_compression(compressor, classifier, dev_loader, device)\n",
        "    logger.info(f\"Epoch {epoch} Dev: acc={dev_metrics['acc']:.4f}, f1={dev_metrics['f1']:.4f}, auc={dev_metrics['auc']}\")\n",
        "\n",
        "    # Save best model based on dev F1\n",
        "    if dev_metrics['f1'] > best_dev_f1:\n",
        "        best_dev_f1 = dev_metrics['f1']\n",
        "        torch.save({\n",
        "            \"compressor_state\": compressor.state_dict(),\n",
        "            \"classifier_state\": classifier.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "            \"dev_metrics\": dev_metrics\n",
        "        }, save_path)\n",
        "        logger.info(f\"✅ Best model saved (Dev F1: {best_dev_f1:.4f})\")\n",
        "\n",
        "# ======================\n",
        "# FINAL EVALUATION ON TEST SET\n",
        "# ======================\n",
        "logger.info(\"\\n\" + \"=\"*60)\n",
        "logger.info(\"FINAL EVALUATION ON TEST SET\")\n",
        "logger.info(\"=\"*60)\n",
        "\n",
        "# Load best model\n",
        "ckpt = torch.load(save_path, map_location=device)\n",
        "compressor.load_state_dict(ckpt['compressor_state'])\n",
        "classifier.load_state_dict(ckpt['classifier_state'])\n",
        "logger.info(f\"Loaded best model from epoch {ckpt.get('epoch', '?')}\")\n",
        "\n",
        "# Evaluate on training set\n",
        "logger.info(\"\\n--- Training Set Results ---\")\n",
        "train_metrics = evaluate_with_hard_compression(compressor, classifier, train_loader, device)\n",
        "logger.info(f\"Accuracy : {train_metrics['acc']:.4f}\")\n",
        "logger.info(f\"Precision: {train_metrics['prec']:.4f}\")\n",
        "logger.info(f\"Recall   : {train_metrics['rec']:.4f}\")\n",
        "logger.info(f\"F1-score : {train_metrics['f1']:.4f}\")\n",
        "logger.info(f\"AUC      : {train_metrics['auc']}\")\n",
        "logger.info(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(train_metrics['y_true'], train_metrics['y_pred']))\n",
        "logger.info(\"Classification Report:\")\n",
        "print(classification_report(train_metrics['y_true'], train_metrics['y_pred'],\n",
        "                           digits=4, zero_division=0))\n",
        "\n",
        "# Evaluate on dev set\n",
        "logger.info(\"\\n--- Dev Set Results ---\")\n",
        "dev_metrics = evaluate_with_hard_compression(compressor, classifier, dev_loader, device)\n",
        "logger.info(f\"Accuracy : {dev_metrics['acc']:.4f}\")\n",
        "logger.info(f\"Precision: {dev_metrics['prec']:.4f}\")\n",
        "logger.info(f\"Recall   : {dev_metrics['rec']:.4f}\")\n",
        "logger.info(f\"F1-score : {dev_metrics['f1']:.4f}\")\n",
        "logger.info(f\"AUC      : {dev_metrics['auc']}\")\n",
        "logger.info(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(dev_metrics['y_true'], dev_metrics['y_pred']))\n",
        "logger.info(\"Classification Report:\")\n",
        "print(classification_report(dev_metrics['y_true'], dev_metrics['y_pred'],\n",
        "                           digits=4, zero_division=0))\n",
        "\n",
        "# Evaluate on eval/test set\n",
        "logger.info(\"\\n--- Test Set Results ---\")\n",
        "eval_metrics = evaluate_with_hard_compression(compressor, classifier, eval_loader, device)\n",
        "logger.info(f\"Accuracy : {eval_metrics['acc']:.4f}\")\n",
        "logger.info(f\"Precision: {eval_metrics['prec']:.4f}\")\n",
        "logger.info(f\"Recall   : {eval_metrics['rec']:.4f}\")\n",
        "logger.info(f\"F1-score : {eval_metrics['f1']:.4f}\")\n",
        "logger.info(f\"AUC      : {eval_metrics['auc']}\")\n",
        "logger.info(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(eval_metrics['y_true'], eval_metrics['y_pred']))\n",
        "logger.info(\"Classification Report:\")\n",
        "print(classification_report(eval_metrics['y_true'], eval_metrics['y_pred'],\n",
        "                           digits=4, zero_division=0))\n",
        "\n",
        "logger.info(\"\\n\" + \"=\"*60)\n",
        "logger.info(\"EVALUATION COMPLETE\")\n",
        "logger.info(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v9lfRu97DW_L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}