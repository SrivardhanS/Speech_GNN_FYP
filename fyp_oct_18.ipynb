{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3lsnldQv3khxkuJMvgi3F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SrivardhanS/Speech_GNN_FYP/blob/main/fyp_oct_18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvL0Mu3UMinF",
        "outputId": "37e22bb5-8184-4e36-91eb-3d44176a77b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.9/542.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.6/792.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing Colab cache for faster access to the 'asvpoof-2019-dataset' dataset.\n",
            "13:07:15 [INFO] Dataset path: /kaggle/input/asvpoof-2019-dataset\n",
            "13:07:16 [INFO] Train protocol sample:\n",
            "    utt_id    speaker_id system_id attack_id     label\n",
            "0  LA_0079  LA_T_1138215         -         -  bonafide\n",
            "1  LA_0079  LA_T_1271820         -         -  bonafide\n",
            "2  LA_0079  LA_T_1272637         -         -  bonafide\n",
            "3  LA_0079  LA_T_1276960         -         -  bonafide\n",
            "4  LA_0079  LA_T_1341447         -         -  bonafide\n",
            "13:07:16 [INFO] Train label distribution:\n",
            "label\n",
            "spoof       22800\n",
            "bonafide     2580\n",
            "Name: count, dtype: int64\n",
            "13:07:16 [INFO] Dev protocol loaded: 24844 samples\n",
            "13:07:16 [INFO] Dev label distribution:\n",
            "label\n",
            "spoof       22296\n",
            "bonafide     2548\n",
            "Name: count, dtype: int64\n",
            "13:07:16 [INFO] Eval protocol loaded: 71237 samples\n",
            "13:07:16 [INFO] Eval label distribution:\n",
            "label\n",
            "spoof       63882\n",
            "bonafide     7355\n",
            "Name: count, dtype: int64\n",
            "13:07:16 [INFO] ✅ Dataset preparation complete! You can now run Cell 2 for training.\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# CELL 1: Dataset Download & Preparation\n",
        "# Run this cell ONCE to download and prepare the dataset\n",
        "# ======================\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install -q torch-spline-conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install -q torch-geometric\n",
        "!pip install -q kaggle librosa\n",
        "\n",
        "import os, sys, logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "\n",
        "# Logging setup\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    datefmt=\"%H:%M:%S\",\n",
        "    handlers=[logging.StreamHandler(sys.stdout)],\n",
        "    force=True\n",
        ")\n",
        "logger = logging.getLogger(\"asvspoof-dataset\")\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"awsaf49/asvpoof-2019-dataset\")\n",
        "logger.info(f\"Dataset path: {path}\")\n",
        "\n",
        "# Set up paths\n",
        "dataset_path = os.path.join(path, \"LA\", \"LA\")\n",
        "proto_dir = os.path.join(dataset_path, \"ASVspoof2019_LA_cm_protocols\")\n",
        "train_proto = os.path.join(proto_dir, \"ASVspoof2019.LA.cm.train.trn.txt\")\n",
        "dev_proto = os.path.join(proto_dir, \"ASVspoof2019.LA.cm.dev.trl.txt\")\n",
        "eval_proto = os.path.join(proto_dir, \"ASVspoof2019.LA.cm.eval.trl.txt\")\n",
        "\n",
        "train_audio_dir = os.path.join(dataset_path, \"ASVspoof2019_LA_train\", \"flac\")\n",
        "dev_audio_dir   = os.path.join(dataset_path, \"ASVspoof2019_LA_dev\", \"flac\")\n",
        "eval_audio_dir  = os.path.join(dataset_path, \"ASVspoof2019_LA_eval\", \"flac\")\n",
        "\n",
        "# Load protocols\n",
        "protocol_df = pd.read_csv(train_proto, sep=\" \", header=None)\n",
        "protocol_df.columns = [\"utt_id\", \"speaker_id\", \"system_id\", \"attack_id\", \"label\"]\n",
        "logger.info(f\"Train protocol sample:\\n{protocol_df.head()}\")\n",
        "logger.info(f\"Train label distribution:\\n{protocol_df['label'].value_counts()}\")\n",
        "\n",
        "dev_df = pd.read_csv(dev_proto, sep=\" \", header=None)\n",
        "dev_df.columns = [\"utt_id\", \"speaker_id\", \"system_id\", \"attack_id\", \"label\"]\n",
        "logger.info(f\"Dev protocol loaded: {len(dev_df)} samples\")\n",
        "logger.info(f\"Dev label distribution:\\n{dev_df['label'].value_counts()}\")\n",
        "\n",
        "eval_df = pd.read_csv(eval_proto, sep=\" \", header=None)\n",
        "eval_df.columns = [\"utt_id\", \"speaker_id\", \"system_id\", \"attack_id\", \"label\"]\n",
        "logger.info(f\"Eval protocol loaded: {len(eval_df)} samples\")\n",
        "logger.info(f\"Eval label distribution:\\n{eval_df['label'].value_counts()}\")\n",
        "\n",
        "logger.info(\"✅ Dataset preparation complete! You can now run Cell 2 for training.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MT8nI-aLMk2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# CELL 2: Model Training & Evaluation - FULLY BALANCED\n",
        "# Uses ALL bonafide samples and matches with equal number of spoof samples\n",
        "# Train: 2580 bonafide + 2580 spoof = 5160 total\n",
        "# Dev: 2548 bonafide + 2548 spoof = 5096 total\n",
        "# Eval: 7355 bonafide + 7355 spoof = 14710 total\n",
        "# ======================\n",
        "\n",
        "import os, sys, logging, random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, confusion_matrix,\n",
        "                             classification_report)\n",
        "\n",
        "# Logging setup\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    datefmt=\"%H:%M:%S\",\n",
        "    handlers=[logging.StreamHandler(sys.stdout)],\n",
        "    force=True\n",
        ")\n",
        "logger = logging.getLogger(\"asvspoof-train\")\n",
        "\n",
        "# ----------------------\n",
        "# DATASET STATISTICS\n",
        "# ----------------------\n",
        "logger.info(\"\\n\" + \"=\"*60)\n",
        "logger.info(\"BALANCED DATASET STRATEGY\")\n",
        "logger.info(\"=\"*60)\n",
        "logger.info(f\"Train: Use ALL {len(protocol_df[protocol_df['label']=='bonafide'])} bonafide + {len(protocol_df[protocol_df['label']=='bonafide'])} spoof\")\n",
        "logger.info(f\"Dev: Use ALL {len(dev_df[dev_df['label']=='bonafide'])} bonafide + {len(dev_df[dev_df['label']=='bonafide'])} spoof\")\n",
        "logger.info(f\"Eval: Use ALL {len(eval_df[eval_df['label']=='bonafide'])} bonafide + {len(eval_df[eval_df['label']=='bonafide'])} spoof\")\n",
        "logger.info(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ----------------------\n",
        "# audio -> temporal graph\n",
        "# ----------------------\n",
        "def audio_to_graph(file_path, sr=16000, n_mfcc=13, pool_size=4):\n",
        "    y, _ = librosa.load(file_path, sr=sr)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    T = mfcc.shape[1] // pool_size\n",
        "    if T < 2:\n",
        "        mfcc = np.pad(mfcc, ((0,0),(0, pool_size*2 - mfcc.shape[1])), mode='wrap')\n",
        "        T = mfcc.shape[1] // pool_size\n",
        "    pooled = np.stack([ np.mean(mfcc[:, i*pool_size:(i+1)*pool_size], axis=1) for i in range(T) ])\n",
        "\n",
        "    x = torch.tensor(pooled, dtype=torch.float)\n",
        "    if x.size(0) < 2:\n",
        "        x = torch.cat([x, x], dim=0)\n",
        "    edge_index = torch.tensor([[i,i+1] for i in range(x.size(0)-1)], dtype=torch.long).T\n",
        "    return Data(x=x, edge_index=edge_index)\n",
        "\n",
        "# ----------------------\n",
        "# DifferentiableGraphCompressor\n",
        "# ----------------------\n",
        "class DifferentiableGraphCompressor(nn.Module):\n",
        "    def __init__(self, feature_dim, tau_T=1.0, lambda_id=1.0, lambda_comp=0.1):\n",
        "        super().__init__()\n",
        "        self.a_raw = nn.Parameter(torch.tensor(0.0))\n",
        "        self.tau_T = tau_T\n",
        "        self.lambda_id = lambda_id\n",
        "        self.lambda_comp = lambda_comp\n",
        "        self.speaker_embedding = nn.Sequential(\n",
        "            nn.Linear(feature_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32)\n",
        "        )\n",
        "\n",
        "    def get_alpha(self):\n",
        "        return torch.sigmoid(self.a_raw)\n",
        "\n",
        "    def node_similarity(self, x_u, x_v):\n",
        "        return F.cosine_similarity(x_u.unsqueeze(0), x_v.unsqueeze(0), dim=1)\n",
        "\n",
        "    def neighborhood_similarity(self, x, edge_index, u, v):\n",
        "        def get_neighbors(node):\n",
        "            mask = (edge_index[0] == node)\n",
        "            if mask.any():\n",
        "                return edge_index[1][mask]\n",
        "            else:\n",
        "                return torch.tensor([], dtype=torch.long, device=x.device)\n",
        "\n",
        "        neighbors_u = get_neighbors(u)\n",
        "        neighbors_v = get_neighbors(v)\n",
        "        if neighbors_u.numel() == 0 or neighbors_v.numel() == 0:\n",
        "            return torch.tensor(0.0, device=x.device)\n",
        "        m_u = x[neighbors_u].mean(dim=0)\n",
        "        m_v = x[neighbors_v].mean(dim=0)\n",
        "        return F.cosine_similarity(m_u.unsqueeze(0), m_v.unsqueeze(0), dim=1)\n",
        "\n",
        "    def combined_similarity(self, x, edge_index, u, v):\n",
        "        alpha = self.get_alpha()\n",
        "        sim_x = self.node_similarity(x[u], x[v])\n",
        "        sim_m = self.neighborhood_similarity(x, edge_index, u, v)\n",
        "        return alpha * sim_x + (1 - alpha) * sim_m\n",
        "\n",
        "    def compute_adaptive_thresholds(self, similarities):\n",
        "        tau_1_bar = torch.quantile(similarities, 0.75)\n",
        "        tau_2_bar = torch.quantile(similarities, 0.60)\n",
        "        return tau_1_bar, tau_2_bar\n",
        "\n",
        "    def compute_merge_probabilities(self, x, edge_index, window_size=10):\n",
        "        num_nodes = x.size(0)\n",
        "        merge_probs = torch.zeros(num_nodes, device=x.device)\n",
        "        all_similarities = []\n",
        "\n",
        "        for t in range(1, num_nodes - 1):\n",
        "            for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                if t + k >= num_nodes - 1:\n",
        "                    continue\n",
        "                try:\n",
        "                    s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                    s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                    s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                    all_similarities.extend([s1, s2, s3])\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "        if len(all_similarities) == 0:\n",
        "            return merge_probs\n",
        "\n",
        "        similarities_tensor = torch.stack(all_similarities).view(-1)\n",
        "        tau_1_bar, tau_2_bar = self.compute_adaptive_thresholds(similarities_tensor)\n",
        "\n",
        "        for t in range(1, num_nodes - 1):\n",
        "            max_prob = 0.0\n",
        "            for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                if t + k >= num_nodes - 1:\n",
        "                    continue\n",
        "                try:\n",
        "                    s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                    s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                    s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                    gate1 = torch.sigmoid((s1 - tau_1_bar) / self.tau_T)\n",
        "                    gate2 = torch.sigmoid((s2 - tau_2_bar) / self.tau_T)\n",
        "                    gate3 = torch.sigmoid((s3 - tau_2_bar) / self.tau_T)\n",
        "                    prob = gate1 * gate2 * gate3\n",
        "                    max_prob = max(max_prob, prob.item())\n",
        "                except Exception:\n",
        "                    continue\n",
        "            merge_probs[t] = max_prob\n",
        "\n",
        "        return merge_probs\n",
        "\n",
        "    def differentiable_compression(self, x, edge_index):\n",
        "        merge_probs = self.compute_merge_probabilities(x, edge_index)\n",
        "        x_compressed = x.clone()\n",
        "        num_nodes = x.size(0)\n",
        "        for t in range(1, num_nodes - 1):\n",
        "            if merge_probs[t] > 0:\n",
        "                best_k = 1\n",
        "                best_sim = -1\n",
        "                for k in range(1, min(10, num_nodes - t)):\n",
        "                    if t + k >= num_nodes: break\n",
        "                    try:\n",
        "                        sim = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                        if sim > best_sim:\n",
        "                            best_sim = sim\n",
        "                            best_k = k\n",
        "                    except Exception:\n",
        "                        continue\n",
        "                if t + best_k < num_nodes:\n",
        "                    p = merge_probs[t]\n",
        "                    interpolated = (x[t] + x[t + best_k]) / 2\n",
        "                    x_compressed[t] = (1 - p) * x[t] + p * interpolated\n",
        "        return x_compressed, merge_probs\n",
        "\n",
        "    def speaker_identity_loss(self, x_original, x_compressed):\n",
        "        g_original = self.speaker_embedding(x_original.mean(dim=0))\n",
        "        g_compressed = self.speaker_embedding(x_compressed.mean(dim=0))\n",
        "        cos_sim = F.cosine_similarity(g_original.unsqueeze(0), g_compressed.unsqueeze(0))\n",
        "        return 1 - cos_sim\n",
        "\n",
        "    def compression_loss(self, merge_probs):\n",
        "        return (1 - merge_probs).mean()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x_compressed, merge_probs = self.differentiable_compression(x, edge_index)\n",
        "        L_id = self.speaker_identity_loss(x, x_compressed)\n",
        "        L_comp = self.compression_loss(merge_probs)\n",
        "        total_loss = self.lambda_id * L_id + self.lambda_comp * L_comp\n",
        "        return {\n",
        "            'compressed_features': x_compressed,\n",
        "            'merge_probs': merge_probs,\n",
        "            'loss': total_loss,\n",
        "            'loss_id': L_id,\n",
        "            'loss_comp': L_comp,\n",
        "            'alpha': self.get_alpha()\n",
        "        }\n",
        "\n",
        "    def hard_compression_inference(self, x, edge_index, window_size=10):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            alpha = self.get_alpha().item()\n",
        "            num_nodes = x.size(0)\n",
        "            to_remove = set()\n",
        "            all_similarities = []\n",
        "            for t in range(1, num_nodes - 1):\n",
        "                for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                    if t + k >= num_nodes - 1: continue\n",
        "                    try:\n",
        "                        s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                        s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                        s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                        all_similarities.extend([s1, s2, s3])\n",
        "                    except Exception:\n",
        "                        continue\n",
        "            if all_similarities:\n",
        "                similarities_tensor = torch.stack(all_similarities).view(-1)\n",
        "                tau_1_hat, tau_2_hat = self.compute_adaptive_thresholds(similarities_tensor)\n",
        "                for t in range(1, num_nodes - 1):\n",
        "                    if t in to_remove: continue\n",
        "                    for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                        if t + k >= num_nodes - 1 or any(n in to_remove for n in [t, t+k, t-1, t+k-1, t+1, t+k+1]):\n",
        "                            continue\n",
        "                        try:\n",
        "                            s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                            s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                            s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                            if s1 >= tau_1_hat and s2 >= tau_2_hat and s3 >= tau_2_hat:\n",
        "                                to_remove.add(t)\n",
        "                                break\n",
        "                        except Exception:\n",
        "                            continue\n",
        "            remaining_indices = [i for i in range(num_nodes) if i not in to_remove]\n",
        "            x_new = x[remaining_indices]\n",
        "            index_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(remaining_indices)}\n",
        "            new_edges = []\n",
        "            for i in range(edge_index.size(1)):\n",
        "                src, dst = edge_index[0, i].item(), edge_index[1, i].item()\n",
        "                if src not in to_remove and dst not in to_remove:\n",
        "                    new_edges.append([index_mapping[src], index_mapping[dst]])\n",
        "            if new_edges:\n",
        "                edge_index_new = torch.tensor(new_edges, dtype=torch.long).T\n",
        "            else:\n",
        "                edge_index_new = torch.empty((2, 0), dtype=torch.long)\n",
        "            compressed_data = Data(x=x_new, edge_index=edge_index_new)\n",
        "            return compressed_data, to_remove, alpha\n",
        "\n",
        "# ----------------------\n",
        "# GCN classifier\n",
        "# ----------------------\n",
        "class GCNClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.fc = nn.Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return torch.sigmoid(self.fc(x)).view(-1)\n",
        "\n",
        "# ----------------------\n",
        "# Build graphs - FULLY BALANCED (use ALL bonafide)\n",
        "# ----------------------\n",
        "def build_fully_balanced_graphs(df, audio_dir, n_mfcc=13, pool_size=4):\n",
        "    \"\"\"\n",
        "    Uses ALL bonafide samples and randomly samples equal number of spoof samples\n",
        "    \"\"\"\n",
        "    bonafide_df = df[df['label'] == 'bonafide']\n",
        "    spoof_df = df[df['label'] == 'spoof']\n",
        "\n",
        "    # Use ALL bonafide\n",
        "    num_bonafide = len(bonafide_df)\n",
        "\n",
        "    # Sample equal number of spoof\n",
        "    spoof_sample = spoof_df.sample(n=num_bonafide, random_state=42)\n",
        "\n",
        "    # Combine and shuffle\n",
        "    balanced_df = pd.concat([bonafide_df, spoof_sample]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    logger.info(f\"Balanced dataset: {num_bonafide} bonafide + {len(spoof_sample)} spoof = {len(balanced_df)} total\")\n",
        "\n",
        "    graphs = []\n",
        "    failed = 0\n",
        "    for i, row in balanced_df.iterrows():\n",
        "        utt = row['speaker_id']\n",
        "        file_path = os.path.join(audio_dir, f\"{utt}.flac\")\n",
        "        if not os.path.isfile(file_path):\n",
        "            failed += 1\n",
        "            continue\n",
        "        try:\n",
        "            g = audio_to_graph(file_path, n_mfcc=n_mfcc, pool_size=pool_size)\n",
        "            g.y = torch.tensor(1 if row['label']=='bonafide' else 0, dtype=torch.float)\n",
        "            graphs.append(g)\n",
        "        except Exception as e:\n",
        "            failed += 1\n",
        "            continue\n",
        "\n",
        "        if (i + 1) % 500 == 0:\n",
        "            logger.info(f\"  Processed {i+1}/{len(balanced_df)} samples...\")\n",
        "\n",
        "    labels = [int(g.y.item()) for g in graphs]\n",
        "    logger.info(f\"Final graphs: bonafide={labels.count(1)}, spoof={labels.count(0)} (failed={failed})\")\n",
        "    return graphs\n",
        "\n",
        "# ----------------------\n",
        "# Training + evaluation\n",
        "# ----------------------\n",
        "def train_epoch(compressor, classifier, loader, optimizer, criterion, device, epoch, lambda_comp_loss):\n",
        "    classifier.train()\n",
        "    compressor.train()\n",
        "    total_cls_loss = 0.0\n",
        "    total_comp_loss = 0.0\n",
        "    n = 0\n",
        "    for batch_idx, batch in enumerate(loader):\n",
        "        batch = batch.to(device)\n",
        "        x = batch.x\n",
        "        edge_index = batch.edge_index\n",
        "\n",
        "        comp_res = compressor(x, edge_index)\n",
        "        x_compressed = comp_res['compressed_features']\n",
        "        comp_loss = comp_res['loss']\n",
        "\n",
        "        compressed_data = Data(x=x_compressed, edge_index=edge_index, y=batch.y,\n",
        "                              batch=torch.zeros(x_compressed.size(0), dtype=torch.long, device=device))\n",
        "        compressed_data = compressed_data.to(device)\n",
        "\n",
        "        pred = classifier(compressed_data)\n",
        "        cls_loss = criterion(pred, batch.y)\n",
        "\n",
        "        loss = cls_loss + lambda_comp_loss * comp_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_cls_loss += cls_loss.item()\n",
        "        total_comp_loss += comp_loss.item()\n",
        "        n += 1\n",
        "\n",
        "        if (batch_idx + 1) % 500 == 0:\n",
        "            logger.info(f\"Epoch {epoch} | Batch {batch_idx+1}/{len(loader)} | cls_loss={cls_loss.item():.4f} comp_loss={comp_loss.item():.4f}\")\n",
        "\n",
        "    return total_cls_loss / n, total_comp_loss / n\n",
        "\n",
        "def evaluate_with_hard_compression(compressor, classifier, loader, device):\n",
        "    classifier.eval()\n",
        "    compressor.eval()\n",
        "    y_true, y_pred, y_prob = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            compressed_data, removed, alpha = compressor.hard_compression_inference(batch.x, batch.edge_index)\n",
        "            compressed_data.y = batch.y.cpu()\n",
        "            compressed_data.batch = torch.zeros(compressed_data.x.size(0), dtype=torch.long)\n",
        "            compressed_data = compressed_data.to(device)\n",
        "\n",
        "            prob = classifier(compressed_data)\n",
        "            pred = (prob >= 0.5).long()\n",
        "            y_true.append(int(batch.y.cpu().item()))\n",
        "            y_pred.append(int(pred.cpu().item()))\n",
        "            y_prob.append(float(prob.cpu().item()))\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_true, y_prob) if len(set(y_true)) > 1 else float('nan')\n",
        "    return {\"acc\":acc, \"prec\":prec, \"rec\":rec, \"f1\":f1, \"auc\":auc,\n",
        "            \"y_true\": y_true, \"y_pred\": y_pred, \"y_prob\": y_prob}\n",
        "\n",
        "\n",
        "# ======================\n",
        "# TRAINING STARTS HERE\n",
        "# ======================\n",
        "save_path = \"/content/gcn_compressed_asvspoof.pth\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger.info(f\"Using device: {device}\")\n",
        "\n",
        "# Build FULLY BALANCED datasets\n",
        "logger.info(\"\\nBuilding FULLY BALANCED training graphs...\")\n",
        "train_graphs = build_fully_balanced_graphs(protocol_df, train_audio_dir)\n",
        "train_loader = DataLoader(train_graphs, batch_size=1, shuffle=True)\n",
        "\n",
        "logger.info(\"\\nBuilding FULLY BALANCED dev graphs...\")\n",
        "dev_graphs = build_fully_balanced_graphs(dev_df, dev_audio_dir)\n",
        "dev_loader = DataLoader(dev_graphs, batch_size=1, shuffle=False)\n",
        "\n",
        "logger.info(\"\\nBuilding FULLY BALANCED eval graphs...\")\n",
        "eval_graphs = build_fully_balanced_graphs(eval_df, eval_audio_dir)\n",
        "eval_loader = DataLoader(eval_graphs, batch_size=1, shuffle=False)\n",
        "\n",
        "# Initialize models\n",
        "feature_dim = 13\n",
        "compressor = DifferentiableGraphCompressor(feature_dim, tau_T=1.0, lambda_id=1.0, lambda_comp=0.05).to(device)\n",
        "classifier = GCNClassifier(in_channels=feature_dim, hidden_channels=32).to(device)\n",
        "\n",
        "# Training setup - BALANCED LOSS (no weighting needed since data is balanced)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(\n",
        "    list(compressor.parameters()) + list(classifier.parameters()), lr=1e-3\n",
        ")\n",
        "lambda_comp_loss = 0.1\n",
        "epochs = 6\n",
        "\n",
        "# Train with validation\n",
        "logger.info(\"\\n\" + \"=\"*60)\n",
        "logger.info(\"STARTING TRAINING ON FULLY BALANCED DATASET\")\n",
        "logger.info(\"=\"*60)\n",
        "\n",
        "best_dev_f1 = 0.0\n",
        "for epoch in range(1, epochs + 1):\n",
        "    cls_loss, comp_loss = train_epoch(\n",
        "        compressor, classifier, train_loader, optimizer, criterion, device, epoch, lambda_comp_loss\n",
        "    )\n",
        "    logger.info(f\"Epoch {epoch}: cls_loss={cls_loss:.4f} | comp_loss={comp_loss:.4f}\")\n",
        "\n",
        "    dev_metrics = evaluate_with_hard_compression(compressor, classifier, dev_loader, device)\n",
        "    logger.info(f\"Epoch {epoch} Dev: acc={dev_metrics['acc']:.4f}, f1={dev_metrics['f1']:.4f}, auc={dev_metrics['auc']}\")\n",
        "\n",
        "    if dev_metrics['f1'] > best_dev_f1:\n",
        "        best_dev_f1 = dev_metrics['f1']\n",
        "        torch.save({\n",
        "            \"compressor_state\": compressor.state_dict(),\n",
        "            \"classifier_state\": classifier.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "            \"dev_metrics\": dev_metrics\n",
        "        }, save_path)\n",
        "        logger.info(f\"✅ Best model saved (Dev F1: {best_dev_f1:.4f})\")\n",
        "\n",
        "# ======================\n",
        "# FINAL EVALUATION\n",
        "# ======================\n",
        "logger.info(\"\\n\" + \"=\"*60)\n",
        "logger.info(\"FINAL EVALUATION ON ALL SETS\")\n",
        "logger.info(\"=\"*60)\n",
        "\n",
        "ckpt = torch.load(save_path, map_location=device, weights_only=False)\n",
        "compressor.load_state_dict(ckpt['compressor_state'])\n",
        "classifier.load_state_dict(ckpt['classifier_state'])\n",
        "logger.info(f\"Loaded best model from epoch {ckpt.get('epoch', '?')}\")\n",
        "\n",
        "# Evaluate on training set\n",
        "logger.info(\"\\n--- Training Set Results ---\")\n",
        "train_metrics = evaluate_with_hard_compression(compressor, classifier, train_loader, device)\n",
        "logger.info(f\"Accuracy : {train_metrics['acc']:.4f}\")\n",
        "logger.info(f\"Precision: {train_metrics['prec']:.4f}\")\n",
        "logger.info(f\"Recall   : {train_metrics['rec']:.4f}\")\n",
        "logger.info(f\"F1-score : {train_metrics['f1']:.4f}\")\n",
        "logger.info(f\"AUC      : {train_metrics['auc']}\")\n",
        "logger.info(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(train_metrics['y_true'], train_metrics['y_pred']))\n",
        "logger.info(\"Classification Report:\")\n",
        "print(classification_report(train_metrics['y_true'], train_metrics['y_pred'],\n",
        "                           target_names=['spoof', 'bonafide'], digits=4, zero_division=0))\n",
        "\n",
        "# Evaluate on dev set\n",
        "logger.info(\"\\n--- Dev Set Results ---\")\n",
        "dev_metrics = evaluate_with_hard_compression(compressor, classifier, dev_loader, device)\n",
        "logger.info(f\"Accuracy : {dev_metrics['acc']:.4f}\")\n",
        "logger.info(f\"Precision: {dev_metrics['prec']:.4f}\")\n",
        "logger.info(f\"Recall   : {dev_metrics['rec']:.4f}\")\n",
        "logger.info(f\"F1-score : {dev_metrics['f1']:.4f}\")\n",
        "logger.info(f\"AUC      : {dev_metrics['auc']}\")\n",
        "logger.info(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(dev_metrics['y_true'], dev_metrics['y_pred']))\n",
        "logger.info(\"Classification Report:\")\n",
        "print(classification_report(dev_metrics['y_true'], dev_metrics['y_pred'],\n",
        "                           target_names=['spoof', 'bonafide'], digits=4, zero_division=0))\n",
        "\n",
        "# Evaluate on test/eval set\n",
        "logger.info(\"\\n--- Test Set Results ---\")\n",
        "eval_metrics = evaluate_with_hard_compression(compressor, classifier, eval_loader, device)\n",
        "logger.info(f\"Accuracy : {eval_metrics['acc']:.4f}\")\n",
        "logger.info(f\"Precision: {eval_metrics['prec']:.4f}\")\n",
        "logger.info(f\"Recall   : {eval_metrics['rec']:.4f}\")\n",
        "logger.info(f\"F1-score : {eval_metrics['f1']:.4f}\")\n",
        "logger.info(f\"AUC      : {eval_metrics['auc']}\")\n",
        "logger.info(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(eval_metrics['y_true'], eval_metrics['y_pred']))\n",
        "logger.info(\"Classification Report:\")\n",
        "print(classification_report(eval_metrics['y_true'], eval_metrics['y_pred'],\n",
        "                           target_names=['spoof', 'bonafide'], digits=4, zero_division=0))\n",
        "\n",
        "logger.info(\"\\n\" + \"=\"*60)\n",
        "logger.info(\"EVALUATION COMPLETE\")\n",
        "logger.info(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eS6YSMQM_7h",
        "outputId": "f8cf75c7-3480-4341-82ce-c4c0654cd73d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13:07:48 [INFO] \n",
            "============================================================\n",
            "13:07:48 [INFO] BALANCED DATASET STRATEGY\n",
            "13:07:48 [INFO] ============================================================\n",
            "13:07:48 [INFO] Train: Use ALL 2580 bonafide + 2580 spoof\n",
            "13:07:48 [INFO] Dev: Use ALL 2548 bonafide + 2548 spoof\n",
            "13:07:48 [INFO] Eval: Use ALL 7355 bonafide + 7355 spoof\n",
            "13:07:48 [INFO] ============================================================\n",
            "\n",
            "13:07:48 [INFO] Using device: cpu\n",
            "13:07:48 [INFO] \n",
            "Building FULLY BALANCED training graphs...\n",
            "13:07:48 [INFO] Balanced dataset: 2580 bonafide + 2580 spoof = 5160 total\n",
            "13:08:20 [INFO]   Processed 500/5160 samples...\n",
            "13:08:34 [INFO]   Processed 1000/5160 samples...\n",
            "13:08:48 [INFO]   Processed 1500/5160 samples...\n",
            "13:09:02 [INFO]   Processed 2000/5160 samples...\n",
            "13:09:16 [INFO]   Processed 2500/5160 samples...\n",
            "13:09:31 [INFO]   Processed 3000/5160 samples...\n",
            "13:09:46 [INFO]   Processed 3500/5160 samples...\n",
            "13:10:00 [INFO]   Processed 4000/5160 samples...\n",
            "13:10:14 [INFO]   Processed 4500/5160 samples...\n",
            "13:10:29 [INFO]   Processed 5000/5160 samples...\n",
            "13:10:33 [INFO] Final graphs: bonafide=2580, spoof=2580 (failed=0)\n",
            "13:10:33 [INFO] \n",
            "Building FULLY BALANCED dev graphs...\n",
            "13:10:33 [INFO] Balanced dataset: 2548 bonafide + 2548 spoof = 5096 total\n",
            "13:10:48 [INFO]   Processed 500/5096 samples...\n",
            "13:11:01 [INFO]   Processed 1000/5096 samples...\n",
            "13:11:15 [INFO]   Processed 1500/5096 samples...\n",
            "13:11:29 [INFO]   Processed 2000/5096 samples...\n",
            "13:11:43 [INFO]   Processed 2500/5096 samples...\n",
            "13:11:57 [INFO]   Processed 3000/5096 samples...\n",
            "13:12:12 [INFO]   Processed 3500/5096 samples...\n",
            "13:12:26 [INFO]   Processed 4000/5096 samples...\n",
            "13:12:40 [INFO]   Processed 4500/5096 samples...\n",
            "13:12:56 [INFO]   Processed 5000/5096 samples...\n",
            "13:12:58 [INFO] Final graphs: bonafide=2548, spoof=2548 (failed=0)\n",
            "13:12:58 [INFO] \n",
            "Building FULLY BALANCED eval graphs...\n",
            "13:12:58 [INFO] Balanced dataset: 7355 bonafide + 7355 spoof = 14710 total\n",
            "13:13:13 [INFO]   Processed 500/14710 samples...\n",
            "13:13:27 [INFO]   Processed 1000/14710 samples...\n",
            "13:13:41 [INFO]   Processed 1500/14710 samples...\n",
            "13:13:56 [INFO]   Processed 2000/14710 samples...\n",
            "13:14:11 [INFO]   Processed 2500/14710 samples...\n",
            "13:14:25 [INFO]   Processed 3000/14710 samples...\n",
            "13:14:39 [INFO]   Processed 3500/14710 samples...\n",
            "13:14:55 [INFO]   Processed 4000/14710 samples...\n",
            "13:15:09 [INFO]   Processed 4500/14710 samples...\n",
            "13:15:23 [INFO]   Processed 5000/14710 samples...\n",
            "13:15:38 [INFO]   Processed 5500/14710 samples...\n",
            "13:15:52 [INFO]   Processed 6000/14710 samples...\n",
            "13:16:06 [INFO]   Processed 6500/14710 samples...\n",
            "13:16:21 [INFO]   Processed 7000/14710 samples...\n",
            "13:16:36 [INFO]   Processed 7500/14710 samples...\n",
            "13:16:50 [INFO]   Processed 8000/14710 samples...\n",
            "13:17:05 [INFO]   Processed 8500/14710 samples...\n",
            "13:17:19 [INFO]   Processed 9000/14710 samples...\n",
            "13:17:35 [INFO]   Processed 9500/14710 samples...\n",
            "13:17:49 [INFO]   Processed 10000/14710 samples...\n",
            "13:18:03 [INFO]   Processed 10500/14710 samples...\n",
            "13:18:17 [INFO]   Processed 11000/14710 samples...\n",
            "13:18:31 [INFO]   Processed 11500/14710 samples...\n",
            "13:18:46 [INFO]   Processed 12000/14710 samples...\n",
            "13:19:00 [INFO]   Processed 12500/14710 samples...\n",
            "13:19:14 [INFO]   Processed 13000/14710 samples...\n",
            "13:19:28 [INFO]   Processed 13500/14710 samples...\n",
            "13:19:42 [INFO]   Processed 14000/14710 samples...\n",
            "13:19:56 [INFO]   Processed 14500/14710 samples...\n",
            "13:20:01 [INFO] Final graphs: bonafide=7355, spoof=7355 (failed=0)\n",
            "13:20:01 [INFO] \n",
            "============================================================\n",
            "13:20:01 [INFO] STARTING TRAINING ON FULLY BALANCED DATASET\n",
            "13:20:01 [INFO] ============================================================\n",
            "13:23:16 [INFO] Epoch 1 | Batch 500/5160 | cls_loss=0.0123 comp_loss=0.0444\n",
            "13:26:32 [INFO] Epoch 1 | Batch 1000/5160 | cls_loss=4.0865 comp_loss=0.0443\n",
            "13:29:49 [INFO] Epoch 1 | Batch 1500/5160 | cls_loss=0.0239 comp_loss=0.0443\n",
            "13:33:09 [INFO] Epoch 1 | Batch 2000/5160 | cls_loss=2.7040 comp_loss=0.0444\n",
            "13:36:34 [INFO] Epoch 1 | Batch 2500/5160 | cls_loss=0.3606 comp_loss=0.0444\n",
            "13:39:56 [INFO] Epoch 1 | Batch 3000/5160 | cls_loss=0.0200 comp_loss=0.0440\n",
            "13:43:16 [INFO] Epoch 1 | Batch 3500/5160 | cls_loss=0.4209 comp_loss=0.0440\n",
            "13:46:28 [INFO] Epoch 1 | Batch 4000/5160 | cls_loss=0.0013 comp_loss=0.0452\n",
            "13:49:41 [INFO] Epoch 1 | Batch 4500/5160 | cls_loss=1.5128 comp_loss=0.0440\n",
            "13:53:06 [INFO] Epoch 1 | Batch 5000/5160 | cls_loss=0.0026 comp_loss=0.0445\n",
            "13:54:08 [INFO] Epoch 1: cls_loss=0.5983 | comp_loss=0.0444\n",
            "14:12:55 [INFO] Epoch 1 Dev: acc=0.8122, f1=0.7972, auc=0.9088191187596885\n",
            "14:12:55 [INFO] ✅ Best model saved (Dev F1: 0.7972)\n",
            "14:16:07 [INFO] Epoch 2 | Batch 500/5160 | cls_loss=1.8694 comp_loss=0.0442\n",
            "14:19:28 [INFO] Epoch 2 | Batch 1000/5160 | cls_loss=1.7041 comp_loss=0.0444\n",
            "14:22:51 [INFO] Epoch 2 | Batch 1500/5160 | cls_loss=0.1401 comp_loss=0.0449\n",
            "14:26:12 [INFO] Epoch 2 | Batch 2000/5160 | cls_loss=0.5251 comp_loss=0.0444\n",
            "14:29:23 [INFO] Epoch 2 | Batch 2500/5160 | cls_loss=0.0816 comp_loss=0.0445\n",
            "14:32:44 [INFO] Epoch 2 | Batch 3000/5160 | cls_loss=0.8157 comp_loss=0.0442\n",
            "14:36:08 [INFO] Epoch 2 | Batch 3500/5160 | cls_loss=0.0299 comp_loss=0.0449\n",
            "14:39:18 [INFO] Epoch 2 | Batch 4000/5160 | cls_loss=0.0105 comp_loss=0.0442\n",
            "14:42:29 [INFO] Epoch 2 | Batch 4500/5160 | cls_loss=0.2142 comp_loss=0.0441\n",
            "14:45:49 [INFO] Epoch 2 | Batch 5000/5160 | cls_loss=0.1057 comp_loss=0.0443\n",
            "14:46:55 [INFO] Epoch 2: cls_loss=0.2937 | comp_loss=0.0444\n",
            "15:05:42 [INFO] Epoch 2 Dev: acc=0.8385, f1=0.8295, auc=0.9154558997853459\n",
            "15:05:42 [INFO] ✅ Best model saved (Dev F1: 0.8295)\n",
            "15:09:06 [INFO] Epoch 3 | Batch 500/5160 | cls_loss=0.2132 comp_loss=0.0446\n",
            "15:12:24 [INFO] Epoch 3 | Batch 1000/5160 | cls_loss=0.0322 comp_loss=0.0441\n",
            "15:15:39 [INFO] Epoch 3 | Batch 1500/5160 | cls_loss=0.0082 comp_loss=0.0448\n",
            "15:19:00 [INFO] Epoch 3 | Batch 2000/5160 | cls_loss=0.0600 comp_loss=0.0443\n",
            "15:22:21 [INFO] Epoch 3 | Batch 2500/5160 | cls_loss=0.0002 comp_loss=0.0445\n",
            "15:25:39 [INFO] Epoch 3 | Batch 3000/5160 | cls_loss=0.0148 comp_loss=0.0443\n",
            "15:29:00 [INFO] Epoch 3 | Batch 3500/5160 | cls_loss=0.0047 comp_loss=0.0443\n",
            "15:32:21 [INFO] Epoch 3 | Batch 4000/5160 | cls_loss=0.0113 comp_loss=0.0444\n",
            "15:35:40 [INFO] Epoch 3 | Batch 4500/5160 | cls_loss=0.0109 comp_loss=0.0445\n",
            "15:38:54 [INFO] Epoch 3 | Batch 5000/5160 | cls_loss=0.0215 comp_loss=0.0441\n",
            "15:39:54 [INFO] Epoch 3: cls_loss=0.2372 | comp_loss=0.0444\n",
            "15:58:41 [INFO] Epoch 3 Dev: acc=0.8110, f1=0.7810, auc=0.9130796247372273\n",
            "16:01:56 [INFO] Epoch 4 | Batch 500/5160 | cls_loss=0.0009 comp_loss=0.0442\n",
            "16:05:18 [INFO] Epoch 4 | Batch 1000/5160 | cls_loss=0.2967 comp_loss=0.0443\n",
            "16:08:33 [INFO] Epoch 4 | Batch 1500/5160 | cls_loss=0.0780 comp_loss=0.0442\n",
            "16:11:45 [INFO] Epoch 4 | Batch 2000/5160 | cls_loss=0.0078 comp_loss=0.0441\n",
            "16:15:10 [INFO] Epoch 4 | Batch 2500/5160 | cls_loss=2.1295 comp_loss=0.0442\n",
            "16:18:34 [INFO] Epoch 4 | Batch 3000/5160 | cls_loss=0.0018 comp_loss=0.0442\n",
            "16:21:55 [INFO] Epoch 4 | Batch 3500/5160 | cls_loss=0.7784 comp_loss=0.0441\n",
            "16:25:17 [INFO] Epoch 4 | Batch 4000/5160 | cls_loss=0.0241 comp_loss=0.0459\n",
            "16:28:30 [INFO] Epoch 4 | Batch 4500/5160 | cls_loss=0.0076 comp_loss=0.0449\n",
            "16:31:45 [INFO] Epoch 4 | Batch 5000/5160 | cls_loss=0.0929 comp_loss=0.0440\n",
            "16:32:51 [INFO] Epoch 4: cls_loss=0.2094 | comp_loss=0.0444\n",
            "16:51:51 [INFO] Epoch 4 Dev: acc=0.8175, f1=0.7898, auc=0.9098757544317086\n",
            "16:55:15 [INFO] Epoch 5 | Batch 500/5160 | cls_loss=0.0302 comp_loss=0.0446\n",
            "16:58:22 [INFO] Epoch 5 | Batch 1000/5160 | cls_loss=1.0303 comp_loss=0.0443\n",
            "17:01:44 [INFO] Epoch 5 | Batch 1500/5160 | cls_loss=0.0133 comp_loss=0.0444\n",
            "17:05:02 [INFO] Epoch 5 | Batch 2000/5160 | cls_loss=0.0212 comp_loss=0.0444\n",
            "17:08:27 [INFO] Epoch 5 | Batch 2500/5160 | cls_loss=0.0027 comp_loss=0.0451\n",
            "17:11:46 [INFO] Epoch 5 | Batch 3000/5160 | cls_loss=0.0005 comp_loss=0.0443\n",
            "17:15:03 [INFO] Epoch 5 | Batch 3500/5160 | cls_loss=1.3527 comp_loss=0.0441\n",
            "17:18:11 [INFO] Epoch 5 | Batch 4000/5160 | cls_loss=0.2402 comp_loss=0.0445\n",
            "17:21:26 [INFO] Epoch 5 | Batch 4500/5160 | cls_loss=0.0032 comp_loss=0.0445\n",
            "17:24:52 [INFO] Epoch 5 | Batch 5000/5160 | cls_loss=0.0968 comp_loss=0.0442\n",
            "17:25:57 [INFO] Epoch 5: cls_loss=0.1896 | comp_loss=0.0444\n",
            "17:44:45 [INFO] Epoch 5 Dev: acc=0.8397, f1=0.8249, auc=0.9181534013194699\n",
            "17:48:04 [INFO] Epoch 6 | Batch 500/5160 | cls_loss=0.8381 comp_loss=0.0442\n",
            "17:51:33 [INFO] Epoch 6 | Batch 1000/5160 | cls_loss=0.0028 comp_loss=0.0440\n",
            "17:54:54 [INFO] Epoch 6 | Batch 1500/5160 | cls_loss=0.0037 comp_loss=0.0447\n",
            "17:58:10 [INFO] Epoch 6 | Batch 2000/5160 | cls_loss=0.0007 comp_loss=0.0448\n",
            "18:01:28 [INFO] Epoch 6 | Batch 2500/5160 | cls_loss=0.9554 comp_loss=0.0447\n",
            "18:04:44 [INFO] Epoch 6 | Batch 3000/5160 | cls_loss=0.0000 comp_loss=0.0443\n",
            "18:08:02 [INFO] Epoch 6 | Batch 3500/5160 | cls_loss=0.0011 comp_loss=0.0439\n",
            "18:11:18 [INFO] Epoch 6 | Batch 4000/5160 | cls_loss=0.0130 comp_loss=0.0443\n",
            "18:14:40 [INFO] Epoch 6 | Batch 4500/5160 | cls_loss=0.0007 comp_loss=0.0440\n",
            "18:18:02 [INFO] Epoch 6 | Batch 5000/5160 | cls_loss=0.7052 comp_loss=0.0444\n",
            "18:19:05 [INFO] Epoch 6: cls_loss=0.1766 | comp_loss=0.0444\n",
            "18:38:02 [INFO] Epoch 6 Dev: acc=0.8238, f1=0.8055, auc=0.917760936641291\n",
            "18:41:21 [INFO] Epoch 7 | Batch 500/5160 | cls_loss=0.6075 comp_loss=0.0446\n",
            "18:44:44 [INFO] Epoch 7 | Batch 1000/5160 | cls_loss=2.4815 comp_loss=0.0441\n",
            "18:48:05 [INFO] Epoch 7 | Batch 1500/5160 | cls_loss=2.0319 comp_loss=0.0443\n",
            "18:51:26 [INFO] Epoch 7 | Batch 2000/5160 | cls_loss=0.6058 comp_loss=0.0443\n",
            "18:54:54 [INFO] Epoch 7 | Batch 2500/5160 | cls_loss=0.0206 comp_loss=0.0444\n",
            "18:58:10 [INFO] Epoch 7 | Batch 3000/5160 | cls_loss=0.0006 comp_loss=0.0440\n",
            "19:01:35 [INFO] Epoch 7 | Batch 3500/5160 | cls_loss=0.0366 comp_loss=0.0443\n",
            "19:04:54 [INFO] Epoch 7 | Batch 4000/5160 | cls_loss=0.0075 comp_loss=0.0442\n",
            "19:08:18 [INFO] Epoch 7 | Batch 4500/5160 | cls_loss=0.0014 comp_loss=0.0444\n",
            "19:11:41 [INFO] Epoch 7 | Batch 5000/5160 | cls_loss=0.0006 comp_loss=0.0443\n",
            "19:12:45 [INFO] Epoch 7: cls_loss=0.1699 | comp_loss=0.0444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zi80SwihPL1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-lhDBDyeaeX9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}