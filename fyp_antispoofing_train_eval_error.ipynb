{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SrivardhanS/Speech_GNN_FYP/blob/main/fyp_antispoofing_train_eval_error.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install torch-scatter, torch-sparse, torch-cluster, torch-spline-conv\n",
        "#    from the official PyG wheels matching your torch+cuda version.\n",
        "#    (This will pull prebuilt binaries)\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "\n",
        "# 2. Finally install torch-geometric\n",
        "!pip install torch-geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQE31YHihKxB",
        "outputId": "8333a6e9-a571-4349-faf0-b4cbb027d0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt24cpu)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt24cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.2)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.12/dist-packages (1.6.3+pt24cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-cluster) (1.16.2)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.12/dist-packages (1.2.2+pt24cpu)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/gcn_compressed_asvspoof.pth\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "sqNUzY24iYl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"awsaf49/asvpoof-2019-dataset\")\n",
        "print(\"Dataset path:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36H_IsZ0i3jl",
        "outputId": "05fd9493-7303-4be3-e878-2ab1759b6bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'asvpoof-2019-dataset' dataset.\n",
            "Dataset path: /kaggle/input/asvpoof-2019-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# Full: Compression + GCN training for ASVspoof2019 LA\n",
        "# ======================\n",
        "!pip install -q kaggle torch_geometric librosa\n",
        "\n",
        "import os, sys, logging, random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Logging setup (Colab-friendly)\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    datefmt=\"%H:%M:%S\",\n",
        "    handlers=[logging.StreamHandler(sys.stdout)],\n",
        "    force=True\n",
        ")\n",
        "logger = logging.getLogger(\"asvspoof-compress-train\")\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# Dataset / Protocols\n",
        "# ----------------------\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"awsaf49/asvpoof-2019-dataset\")\n",
        "logger.info(f\"Dataset path: {path}\")\n",
        "\n",
        "dataset_path = os.path.join(path, \"LA\", \"LA\")\n",
        "proto_dir = os.path.join(dataset_path, \"ASVspoof2019_LA_cm_protocols\")\n",
        "train_proto = os.path.join(proto_dir, \"ASVspoof2019.LA.cm.train.trn.txt\")\n",
        "\n",
        "train_audio_dir = os.path.join(dataset_path, \"ASVspoof2019_LA_train\", \"flac\")\n",
        "dev_audio_dir   = os.path.join(dataset_path, \"ASVspoof2019_LA_dev\", \"flac\")\n",
        "eval_audio_dir  = os.path.join(dataset_path, \"ASVspoof2019_LA_eval\", \"flac\")\n",
        "\n",
        "protocol_df = pd.read_csv(train_proto, sep=\" \", header=None)\n",
        "protocol_df.columns = [\"utt_id\", \"speaker_id\", \"system_id\", \"attack_id\", \"label\"]\n",
        "logger.info(f\"Protocol sample:\\n{protocol_df.head()}\")\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# audio -> temporal graph\n",
        "# ----------------------\n",
        "def audio_to_graph(file_path, sr=16000, n_mfcc=13, pool_size=4):\n",
        "    # load\n",
        "    y, _ = librosa.load(file_path, sr=sr)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    # pool frames\n",
        "    T = mfcc.shape[1] // pool_size\n",
        "    if T < 2:\n",
        "        # pad/truncate guards\n",
        "        mfcc = np.pad(mfcc, ((0,0),(0, pool_size*2 - mfcc.shape[1])), mode='wrap')\n",
        "        T = mfcc.shape[1] // pool_size\n",
        "    pooled = np.stack([ np.mean(mfcc[:, i*pool_size:(i+1)*pool_size], axis=1) for i in range(T) ])\n",
        "\n",
        "    x = torch.tensor(pooled, dtype=torch.float)        # [nodes, feat]\n",
        "    edge_index = torch.tensor([[i,i+1] for i in range(x.size(0)-1)], dtype=torch.long).T\n",
        "    return Data(x=x, edge_index=edge_index)\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# DifferentiableGraphCompressor (exactly as you provided)\n",
        "# ----------------------\n",
        "class DifferentiableGraphCompressor(nn.Module):\n",
        "    def __init__(self, feature_dim, tau_T=1.0, lambda_id=1.0, lambda_comp=0.1):\n",
        "        super().__init__()\n",
        "        self.a_raw = nn.Parameter(torch.tensor(0.0))\n",
        "        self.tau_T = tau_T\n",
        "        self.lambda_id = lambda_id\n",
        "        self.lambda_comp = lambda_comp\n",
        "        self.speaker_embedding = nn.Sequential(\n",
        "            nn.Linear(feature_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32)\n",
        "        )\n",
        "\n",
        "    def get_alpha(self):\n",
        "        return torch.sigmoid(self.a_raw)\n",
        "\n",
        "    def node_similarity(self, x_u, x_v):\n",
        "        return F.cosine_similarity(x_u.unsqueeze(0), x_v.unsqueeze(0), dim=1)\n",
        "\n",
        "    def neighborhood_similarity(self, x, edge_index, u, v):\n",
        "        def get_neighbors(node):\n",
        "            mask = (edge_index[0] == node)\n",
        "            if mask.any():\n",
        "                return edge_index[1][mask]\n",
        "            else:\n",
        "                return torch.tensor([], dtype=torch.long, device=x.device)\n",
        "\n",
        "        neighbors_u = get_neighbors(u)\n",
        "        neighbors_v = get_neighbors(v)\n",
        "        if neighbors_u.numel() == 0 or neighbors_v.numel() == 0:\n",
        "            return torch.tensor(0.0, device=x.device)\n",
        "        m_u = x[neighbors_u].mean(dim=0)\n",
        "        m_v = x[neighbors_v].mean(dim=0)\n",
        "        return F.cosine_similarity(m_u.unsqueeze(0), m_v.unsqueeze(0), dim=1)\n",
        "\n",
        "    def combined_similarity(self, x, edge_index, u, v):\n",
        "        alpha = self.get_alpha()\n",
        "        sim_x = self.node_similarity(x[u], x[v])\n",
        "        sim_m = self.neighborhood_similarity(x, edge_index, u, v)\n",
        "        return alpha * sim_x + (1 - alpha) * sim_m\n",
        "\n",
        "    def compute_adaptive_thresholds(self, similarities):\n",
        "        tau_1_bar = torch.quantile(similarities, 0.75)\n",
        "        tau_2_bar = torch.quantile(similarities, 0.60)\n",
        "        return tau_1_bar, tau_2_bar\n",
        "\n",
        "    def compute_merge_probabilities(self, x, edge_index, window_size=10):\n",
        "        num_nodes = x.size(0)\n",
        "        merge_probs = torch.zeros(num_nodes, device=x.device)\n",
        "        all_similarities = []\n",
        "\n",
        "        for t in range(1, num_nodes - 1):\n",
        "            for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                if t + k >= num_nodes - 1:\n",
        "                    continue\n",
        "                try:\n",
        "                    s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                    s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                    s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                    all_similarities.extend([s1, s2, s3])\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "        if len(all_similarities) == 0:\n",
        "            return merge_probs\n",
        "\n",
        "        similarities_tensor = torch.stack(all_similarities).view(-1)\n",
        "        tau_1_bar, tau_2_bar = self.compute_adaptive_thresholds(similarities_tensor)\n",
        "\n",
        "        for t in range(1, num_nodes - 1):\n",
        "            max_prob = 0.0\n",
        "            for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                if t + k >= num_nodes - 1:\n",
        "                    continue\n",
        "                try:\n",
        "                    s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                    s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                    s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                    gate1 = torch.sigmoid((s1 - tau_1_bar) / self.tau_T)\n",
        "                    gate2 = torch.sigmoid((s2 - tau_2_bar) / self.tau_T)\n",
        "                    gate3 = torch.sigmoid((s3 - tau_2_bar) / self.tau_T)\n",
        "                    prob = gate1 * gate2 * gate3\n",
        "                    max_prob = max(max_prob, prob.item())\n",
        "                except Exception:\n",
        "                    continue\n",
        "            merge_probs[t] = max_prob\n",
        "\n",
        "        return merge_probs\n",
        "\n",
        "    def differentiable_compression(self, x, edge_index):\n",
        "        merge_probs = self.compute_merge_probabilities(x, edge_index)\n",
        "        x_compressed = x.clone()\n",
        "        num_nodes = x.size(0)\n",
        "        for t in range(1, num_nodes - 1):\n",
        "            if merge_probs[t] > 0:\n",
        "                best_k = 1\n",
        "                best_sim = -1\n",
        "                for k in range(1, min(10, num_nodes - t)):\n",
        "                    if t + k >= num_nodes: break\n",
        "                    try:\n",
        "                        sim = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                        if sim > best_sim:\n",
        "                            best_sim = sim\n",
        "                            best_k = k\n",
        "                    except Exception:\n",
        "                        continue\n",
        "                if t + best_k < num_nodes:\n",
        "                    p = merge_probs[t]\n",
        "                    interpolated = (x[t] + x[t + best_k]) / 2\n",
        "                    x_compressed[t] = (1 - p) * x[t] + p * interpolated\n",
        "        return x_compressed, merge_probs\n",
        "\n",
        "    def speaker_identity_loss(self, x_original, x_compressed):\n",
        "        g_original = self.speaker_embedding(x_original.mean(dim=0))\n",
        "        g_compressed = self.speaker_embedding(x_compressed.mean(dim=0))\n",
        "        cos_sim = F.cosine_similarity(g_original.unsqueeze(0), g_compressed.unsqueeze(0))\n",
        "        return 1 - cos_sim\n",
        "\n",
        "    def compression_loss(self, merge_probs):\n",
        "        return (1 - merge_probs).mean()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x_compressed, merge_probs = self.differentiable_compression(x, edge_index)\n",
        "        L_id = self.speaker_identity_loss(x, x_compressed)\n",
        "        L_comp = self.compression_loss(merge_probs)\n",
        "        total_loss = self.lambda_id * L_id + self.lambda_comp * L_comp\n",
        "        return {\n",
        "            'compressed_features': x_compressed,\n",
        "            'merge_probs': merge_probs,\n",
        "            'loss': total_loss,\n",
        "            'loss_id': L_id,\n",
        "            'loss_comp': L_comp,\n",
        "            'alpha': self.get_alpha()\n",
        "        }\n",
        "\n",
        "    # Hard compression inference helper for single graph\n",
        "    def hard_compression_inference(self, x, edge_index, window_size=10):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            alpha = self.get_alpha().item()\n",
        "            num_nodes = x.size(0)\n",
        "            to_remove = set()\n",
        "            all_similarities = []\n",
        "            for t in range(1, num_nodes - 1):\n",
        "                for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                    if t + k >= num_nodes - 1: continue\n",
        "                    try:\n",
        "                        s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                        s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                        s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                        all_similarities.extend([s1, s2, s3])\n",
        "                    except Exception:\n",
        "                        continue\n",
        "            if all_similarities:\n",
        "                similarities_tensor = torch.stack(all_similarities).view(-1)\n",
        "                tau_1_hat, tau_2_hat = self.compute_adaptive_thresholds(similarities_tensor)\n",
        "                for t in range(1, num_nodes - 1):\n",
        "                    if t in to_remove: continue\n",
        "                    for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                        if t + k >= num_nodes - 1 or any(n in to_remove for n in [t, t+k, t-1, t+k-1, t+1, t+k+1]):\n",
        "                            continue\n",
        "                        try:\n",
        "                            s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                            s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                            s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                            if s1 >= tau_1_hat and s2 >= tau_2_hat and s3 >= tau_2_hat:\n",
        "                                to_remove.add(t)\n",
        "                                break\n",
        "                        except Exception:\n",
        "                            continue\n",
        "            remaining_indices = [i for i in range(num_nodes) if i not in to_remove]\n",
        "            x_new = x[remaining_indices]\n",
        "            index_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(remaining_indices)}\n",
        "            new_edges = []\n",
        "            for i in range(edge_index.size(1)):\n",
        "                src, dst = edge_index[0, i].item(), edge_index[1, i].item()\n",
        "                if src not in to_remove and dst not in to_remove:\n",
        "                    new_edges.append([index_mapping[src], index_mapping[dst]])\n",
        "            if new_edges:\n",
        "                edge_index_new = torch.tensor(new_edges, dtype=torch.long).T\n",
        "            else:\n",
        "                edge_index_new = torch.empty((2, 0), dtype=torch.long)\n",
        "            compressed_data = Data(x=x_new, edge_index=edge_index_new)\n",
        "            return compressed_data, to_remove, alpha\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# GCN classifier\n",
        "# ----------------------\n",
        "class GCNClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.fc = nn.Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return torch.sigmoid(self.fc(x)).view(-1)\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# Build lists of Data (graphs)\n",
        "# ----------------------\n",
        "def build_graph_list(df, audio_dir, limit=None, n_mfcc=13, pool_size=4):\n",
        "    graphs = []\n",
        "    rows = df.reset_index(drop=True)\n",
        "    if limit is not None:\n",
        "        rows = rows.iloc[:limit]\n",
        "    for i, row in rows.iterrows():\n",
        "        utt = row['speaker_id']\n",
        "        file_path = os.path.join(audio_dir, f\"{utt}.flac\")\n",
        "        if not os.path.isfile(file_path):\n",
        "            logger.warning(f\"Missing file {file_path}, skipping\")\n",
        "            continue\n",
        "        g = audio_to_graph(file_path, n_mfcc=n_mfcc, pool_size=pool_size)\n",
        "        g.y = torch.tensor(1 if row['label']=='bonafide' else 0, dtype=torch.float)\n",
        "        graphs.append(g)\n",
        "    return graphs\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# Training + evaluation helpers\n",
        "# ----------------------\n",
        "def train_epoch(compressor, classifier, loader, optimizer, criterion, device, epoch):\n",
        "    classifier.train()\n",
        "    compressor.train()\n",
        "    total_cls_loss = 0.0\n",
        "    total_comp_loss = 0.0\n",
        "    n = 0\n",
        "    for batch_idx, batch in enumerate(loader):\n",
        "        batch = batch.to(device)\n",
        "        # batch_size==1 assumption: batch.batch is zeros vector; find node indices for graph\n",
        "        x = batch.x\n",
        "        edge_index = batch.edge_index\n",
        "\n",
        "        # Run compressor (differentiable)\n",
        "        comp_res = compressor(x, edge_index)\n",
        "        x_compressed = comp_res['compressed_features']\n",
        "        comp_loss = comp_res['loss']\n",
        "\n",
        "        # Replace features in a new Data object and classify\n",
        "        compressed_data = Data(x=x_compressed, edge_index=edge_index, y=batch.y, batch=torch.zeros(x_compressed.size(0), dtype=torch.long, device=device))\n",
        "        compressed_data = compressed_data.to(device)\n",
        "\n",
        "        pred = classifier(compressed_data)\n",
        "        cls_loss = criterion(pred, batch.y)\n",
        "\n",
        "        loss = cls_loss + lambda_comp_loss * comp_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_cls_loss += cls_loss.item()\n",
        "        total_comp_loss += comp_loss.item()\n",
        "        n += 1\n",
        "\n",
        "        if (batch_idx + 1) % 20 == 0:\n",
        "            logger.info(f\"Epoch {epoch} | Batch {batch_idx+1}/{len(loader)} | cls_loss={cls_loss.item():.4f} comp_loss={comp_loss.item():.4f}\")\n",
        "\n",
        "    return total_cls_loss / n, total_comp_loss / n\n",
        "\n",
        "\n",
        "def evaluate_with_hard_compression(compressor, classifier, loader, device):\n",
        "    classifier.eval()\n",
        "    compressor.eval()\n",
        "    y_true, y_pred, y_prob = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            # Hard compression inference\n",
        "            compressed_data, removed, alpha = compressor.hard_compression_inference(batch.x, batch.edge_index)\n",
        "            # attach label and batch vector\n",
        "            compressed_data.y = batch.y.cpu()\n",
        "            compressed_data.batch = torch.zeros(compressed_data.x.size(0), dtype=torch.long)\n",
        "            compressed_data = compressed_data.to(device)\n",
        "\n",
        "            prob = classifier(compressed_data)\n",
        "            pred = (prob >= 0.5).long()\n",
        "            y_true.append(int(batch.y.cpu().item()))\n",
        "            y_pred.append(int(pred.cpu().item()))\n",
        "            y_prob.append(float(prob.cpu().item()))\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_true, y_prob) if len(set(y_true)) > 1 else float('nan')\n",
        "    return {\"acc\":acc, \"prec\":prec, \"rec\":rec, \"f1\":f1, \"auc\":auc}\n",
        "\n",
        "\n",
        "\n",
        "save_path = \"/content/gcn_compressed_asvspoof.pth\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qr2oVA-nJqK",
        "outputId": "4d57560f-065c-45de-ca00-24ac8c5ae8ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'asvpoof-2019-dataset' dataset.\n",
            "14:08:25 [INFO] Dataset path: /kaggle/input/asvpoof-2019-dataset\n",
            "14:08:25 [INFO] Protocol sample:\n",
            "    utt_id    speaker_id system_id attack_id     label\n",
            "0  LA_0079  LA_T_1138215         -         -  bonafide\n",
            "1  LA_0079  LA_T_1271820         -         -  bonafide\n",
            "2  LA_0079  LA_T_1272637         -         -  bonafide\n",
            "3  LA_0079  LA_T_1276960         -         -  bonafide\n",
            "4  LA_0079  LA_T_1341447         -         -  bonafide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# Run compression + GCN training\n",
        "# ======================\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger.info(f\"Using device: {device}\")\n",
        "\n",
        "# Build dataset (limit to few samples for demo — remove limit for full training)\n",
        "train_graphs = build_graph_list(protocol_df, train_audio_dir, limit=10)\n",
        "train_loader = DataLoader(train_graphs, batch_size=1, shuffle=True)\n",
        "\n",
        "# Initialize models\n",
        "feature_dim = 13\n",
        "compressor = DifferentiableGraphCompressor(feature_dim).to(device)\n",
        "classifier = GCNClassifier(in_channels=feature_dim).to(device)\n",
        "\n",
        "# Training setup\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(\n",
        "    list(compressor.parameters()) + list(classifier.parameters()), lr=1e-3\n",
        ")\n",
        "lambda_comp_loss = 0.1\n",
        "epochs = 6  # increase later when GPU runtime allows\n",
        "\n",
        "# Train\n",
        "for epoch in range(1, epochs + 1):\n",
        "    cls_loss, comp_loss = train_epoch(\n",
        "        compressor, classifier, train_loader, optimizer, criterion, device, epoch\n",
        "    )\n",
        "    logger.info(f\"Epoch {epoch}: cls_loss={cls_loss:.4f} | comp_loss={comp_loss:.4f}\")\n",
        "\n",
        "# Evaluate\n",
        "metrics = evaluate_with_hard_compression(compressor, classifier, train_loader, device)\n",
        "logger.info(f\"Evaluation metrics: {metrics}\")\n",
        "\n",
        "# Save model\n",
        "torch.save({\n",
        "    \"compressor_state_dict\": compressor.state_dict(),\n",
        "    \"classifier_state_dict\": classifier.state_dict(),\n",
        "}, save_path)\n",
        "logger.info(f\"✅ Model saved to {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5aREPod16S1",
        "outputId": "1f8420a7-ef29-426d-d410-7dfd91de73e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14:09:20 [INFO] Using device: cpu\n",
            "14:09:24 [INFO] Epoch 1: cls_loss=0.0039 | comp_loss=0.0890\n",
            "14:09:28 [INFO] Epoch 2: cls_loss=0.0000 | comp_loss=0.0890\n",
            "14:09:32 [INFO] Epoch 3: cls_loss=0.0000 | comp_loss=0.0890\n",
            "14:09:36 [INFO] Epoch 4: cls_loss=0.0000 | comp_loss=0.0890\n",
            "14:09:39 [INFO] Epoch 5: cls_loss=0.0000 | comp_loss=0.0890\n",
            "14:09:42 [INFO] Epoch 6: cls_loss=0.0000 | comp_loss=0.0890\n",
            "14:09:44 [INFO] Evaluation metrics: {'acc': 1.0, 'prec': 1.0, 'rec': 1.0, 'f1': 1.0, 'auc': nan}\n",
            "14:09:44 [INFO] ✅ Model saved to /content/gcn_compressed_asvspoof.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hAe40QAhEfI",
        "outputId": "e7e0c486-8ab6-485b-f188-27ac21dc5ec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14:10:10 [INFO] Using device: cpu\n",
            "14:10:10 [INFO] Test protocol contains 71237 rows\n",
            "14:10:10 [INFO] Building test graphs (this may take a few minutes)...\n",
            "14:29:54 [INFO] Built 71237 test graphs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'compressor_state'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1049720256.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;31m# Load checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m \u001b[0mcompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compressor_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier_state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded checkpoint from {save_path} (saved epoch={ckpt.get('epoch','?')}, dev_f1={ckpt.get('dev_f1','?')})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'compressor_state'"
          ]
        }
      ],
      "source": [
        "# Standalone evaluation script for ASVspoof2019 LA (hard-compression + GCN)\n",
        "# Run in a fresh session. Make sure `save_path`, `proto_dir`, `eval_audio_dir` point to real files.\n",
        "\n",
        "import os, sys, logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "# Logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\", datefmt=\"%H:%M:%S\", handlers=[logging.StreamHandler(sys.stdout)])\n",
        "logger = logging.getLogger(\"eval-standalone\")\n",
        "\n",
        "# ----------------------\n",
        "# Configs: update these if different in your environment\n",
        "# ----------------------\n",
        "save_path = \"/content/gcn_compressed_asvspoof.pth\"   # path to saved checkpoint\n",
        "# dataset root / protocol dirs (ensure these are correct)\n",
        "# If you used kagglehub.dataset_download earlier, use the same dataset_path values.\n",
        "# dataset_base = \"/kaggle/input/asvpoof-2019-dataset\"   # change if your dataset is elsewhere\n",
        "dataset_base = \"/root/.cache/kagglehub/datasets/awsaf49/asvpoof-2019-dataset/versions/1\"\n",
        "dataset_path = os.path.join(dataset_base, \"LA\", \"LA\")  # same layout as training session\n",
        "proto_dir = os.path.join(dataset_path, \"ASVspoof2019_LA_cm_protocols\")\n",
        "eval_audio_dir = os.path.join(dataset_path, \"ASVspoof2019_LA_eval\", \"flac\")\n",
        "test_proto = os.path.join(proto_dir, \"ASVspoof2019.LA.cm.eval.trl.txt\")\n",
        "\n",
        "# ----------------------\n",
        "# audio -> temporal graph helper (same logic as training)\n",
        "# ----------------------\n",
        "def audio_to_graph(file_path, sr=16000, n_mfcc=13, pool_size=4):\n",
        "    y, _ = librosa.load(file_path, sr=sr)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "    T = mfcc.shape[1] // pool_size\n",
        "    if T < 2:\n",
        "        mfcc = np.pad(mfcc, ((0,0),(0, pool_size*2 - mfcc.shape[1])), mode='wrap')\n",
        "        T = mfcc.shape[1] // pool_size\n",
        "    pooled = np.stack([ np.mean(mfcc[:, i*pool_size:(i+1)*pool_size], axis=1) for i in range(T) ])\n",
        "    x = torch.tensor(pooled, dtype=torch.float)\n",
        "    if x.size(0) < 2:\n",
        "        # ensure at least 2 nodes (avoid zero-edge)\n",
        "        x = torch.cat([x, x], dim=0)\n",
        "    edge_index = torch.tensor([[i,i+1] for i in range(x.size(0)-1)], dtype=torch.long).T\n",
        "    return Data(x=x, edge_index=edge_index)\n",
        "\n",
        "def build_graph_list(df, audio_dir, limit=None, n_mfcc=13, pool_size=4):\n",
        "    graphs = []\n",
        "    rows = df.reset_index(drop=True)\n",
        "    if limit is not None:\n",
        "        rows = rows.iloc[:limit]\n",
        "    for _, row in rows.iterrows():\n",
        "        utt = row['speaker_id']\n",
        "        file_path = os.path.join(audio_dir, f\"{utt}.flac\")\n",
        "        if not os.path.isfile(file_path):\n",
        "            logger.warning(f\"Missing file {file_path}, skipping\")\n",
        "            continue\n",
        "        g = audio_to_graph(file_path, n_mfcc=n_mfcc, pool_size=pool_size)\n",
        "        g.y = torch.tensor(1 if row['label']=='bonafide' else 0, dtype=torch.float)\n",
        "        graphs.append(g)\n",
        "    return graphs\n",
        "\n",
        "# ----------------------\n",
        "# Model definitions (same as training)\n",
        "# ----------------------\n",
        "class DifferentiableGraphCompressor(nn.Module):\n",
        "    def __init__(self, feature_dim, tau_T=1.0, lambda_id=1.0, lambda_comp=0.1):\n",
        "        super().__init__()\n",
        "        self.a_raw = nn.Parameter(torch.tensor(0.0))\n",
        "        self.tau_T = tau_T\n",
        "        self.lambda_id = lambda_id\n",
        "        self.lambda_comp = lambda_comp\n",
        "        self.speaker_embedding = nn.Sequential(\n",
        "            nn.Linear(feature_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32)\n",
        "        )\n",
        "\n",
        "    def get_alpha(self):\n",
        "        return torch.sigmoid(self.a_raw)\n",
        "\n",
        "    def node_similarity(self, x_u, x_v):\n",
        "        return F.cosine_similarity(x_u.unsqueeze(0), x_v.unsqueeze(0), dim=1)\n",
        "\n",
        "    def neighborhood_similarity(self, x, edge_index, u, v):\n",
        "        def get_neighbors(node):\n",
        "            mask = (edge_index[0] == node)\n",
        "            if mask.any():\n",
        "                return edge_index[1][mask]\n",
        "            else:\n",
        "                return torch.tensor([], dtype=torch.long, device=x.device)\n",
        "        neighbors_u = get_neighbors(u)\n",
        "        neighbors_v = get_neighbors(v)\n",
        "        if neighbors_u.numel() == 0 or neighbors_v.numel() == 0:\n",
        "            return torch.tensor(0.0, device=x.device)\n",
        "        m_u = x[neighbors_u].mean(dim=0)\n",
        "        m_v = x[neighbors_v].mean(dim=0)\n",
        "        return F.cosine_similarity(m_u.unsqueeze(0), m_v.unsqueeze(0), dim=1)\n",
        "\n",
        "    def combined_similarity(self, x, edge_index, u, v):\n",
        "        alpha = self.get_alpha()\n",
        "        sim_x = self.node_similarity(x[u], x[v])\n",
        "        sim_m = self.neighborhood_similarity(x, edge_index, u, v)\n",
        "        return alpha * sim_x + (1 - alpha) * sim_m\n",
        "\n",
        "    def compute_adaptive_thresholds(self, similarities):\n",
        "        tau_1_bar = torch.quantile(similarities, 0.75)\n",
        "        tau_2_bar = torch.quantile(similarities, 0.60)\n",
        "        return tau_1_bar, tau_2_bar\n",
        "\n",
        "    def compute_merge_probabilities(self, x, edge_index, window_size=10):\n",
        "        num_nodes = x.size(0)\n",
        "        merge_probs = torch.zeros(num_nodes, device=x.device)\n",
        "        all_similarities = []\n",
        "        for t in range(1, num_nodes - 1):\n",
        "            for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                if t + k >= num_nodes - 1:\n",
        "                    continue\n",
        "                try:\n",
        "                    s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                    s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                    s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                    all_similarities.extend([s1, s2, s3])\n",
        "                except Exception:\n",
        "                    continue\n",
        "        if len(all_similarities) == 0:\n",
        "            return merge_probs\n",
        "        similarities_tensor = torch.stack(all_similarities).view(-1)\n",
        "        tau_1_bar, tau_2_bar = self.compute_adaptive_thresholds(similarities_tensor)\n",
        "        for t in range(1, num_nodes - 1):\n",
        "            max_prob = 0.0\n",
        "            for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                if t + k >= num_nodes - 1:\n",
        "                    continue\n",
        "                try:\n",
        "                    s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                    s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                    s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                    gate1 = torch.sigmoid((s1 - tau_1_bar) / self.tau_T)\n",
        "                    gate2 = torch.sigmoid((s2 - tau_2_bar) / self.tau_T)\n",
        "                    gate3 = torch.sigmoid((s3 - tau_2_bar) / self.tau_T)\n",
        "                    prob = gate1 * gate2 * gate3\n",
        "                    max_prob = max(max_prob, prob.item())\n",
        "                except Exception:\n",
        "                    continue\n",
        "            merge_probs[t] = max_prob\n",
        "        return merge_probs\n",
        "\n",
        "    def differentiable_compression(self, x, edge_index):\n",
        "        merge_probs = self.compute_merge_probabilities(x, edge_index)\n",
        "        x_compressed = x.clone()\n",
        "        num_nodes = x.size(0)\n",
        "        for t in range(1, num_nodes - 1):\n",
        "            if merge_probs[t] > 0:\n",
        "                best_k = 1\n",
        "                best_sim = -1\n",
        "                for k in range(1, min(10, num_nodes - t)):\n",
        "                    if t + k >= num_nodes: break\n",
        "                    try:\n",
        "                        sim = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                        if sim > best_sim:\n",
        "                            best_sim = sim\n",
        "                            best_k = k\n",
        "                    except Exception:\n",
        "                        continue\n",
        "                if t + best_k < num_nodes:\n",
        "                    p = merge_probs[t]\n",
        "                    interpolated = (x[t] + x[t + best_k]) / 2\n",
        "                    x_compressed[t] = (1 - p) * x[t] + p * interpolated\n",
        "        return x_compressed, merge_probs\n",
        "\n",
        "    def speaker_identity_loss(self, x_original, x_compressed):\n",
        "        g_original = self.speaker_embedding(x_original.mean(dim=0))\n",
        "        g_compressed = self.speaker_embedding(x_compressed.mean(dim=0))\n",
        "        cos_sim = F.cosine_similarity(g_original.unsqueeze(0), g_compressed.unsqueeze(0))\n",
        "        return 1 - cos_sim\n",
        "\n",
        "    def compression_loss(self, merge_probs):\n",
        "        return (1 - merge_probs).mean()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x_compressed, merge_probs = self.differentiable_compression(x, edge_index)\n",
        "        L_id = self.speaker_identity_loss(x, x_compressed)\n",
        "        L_comp = self.compression_loss(merge_probs)\n",
        "        total_loss = self.lambda_id * L_id + self.lambda_comp * L_comp\n",
        "        return {\n",
        "            'compressed_features': x_compressed,\n",
        "            'merge_probs': merge_probs,\n",
        "            'loss': total_loss,\n",
        "            'loss_id': L_id,\n",
        "            'loss_comp': L_comp,\n",
        "            'alpha': self.get_alpha()\n",
        "        }\n",
        "\n",
        "    def hard_compression_inference(self, x, edge_index, window_size=10):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            alpha = self.get_alpha().item()\n",
        "            num_nodes = x.size(0)\n",
        "            to_remove = set()\n",
        "            all_similarities = []\n",
        "            for t in range(1, num_nodes - 1):\n",
        "                for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                    if t + k >= num_nodes - 1: continue\n",
        "                    try:\n",
        "                        s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                        s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                        s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                        all_similarities.extend([s1, s2, s3])\n",
        "                    except Exception:\n",
        "                        continue\n",
        "            if all_similarities:\n",
        "                similarities_tensor = torch.stack(all_similarities).view(-1)\n",
        "                tau_1_hat, tau_2_hat = self.compute_adaptive_thresholds(similarities_tensor)\n",
        "                for t in range(1, num_nodes - 1):\n",
        "                    if t in to_remove: continue\n",
        "                    for k in range(1, min(window_size + 1, num_nodes - t)):\n",
        "                        if t + k >= num_nodes - 1 or any(n in to_remove for n in [t, t+k, t-1, t+k-1, t+1, t+k+1]):\n",
        "                            continue\n",
        "                        try:\n",
        "                            s1 = self.combined_similarity(x, edge_index, t, t + k)\n",
        "                            s2 = self.combined_similarity(x, edge_index, t - 1, t + k - 1)\n",
        "                            s3 = self.combined_similarity(x, edge_index, t + 1, t + k + 1)\n",
        "                            if s1 >= tau_1_hat and s2 >= tau_2_hat and s3 >= tau_2_hat:\n",
        "                                to_remove.add(t)\n",
        "                                break\n",
        "                        except Exception:\n",
        "                            continue\n",
        "            remaining_indices = [i for i in range(num_nodes) if i not in to_remove]\n",
        "            x_new = x[remaining_indices]\n",
        "            index_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(remaining_indices)}\n",
        "            new_edges = []\n",
        "            for i in range(edge_index.size(1)):\n",
        "                src, dst = edge_index[0, i].item(), edge_index[1, i].item()\n",
        "                if src not in to_remove and dst not in to_remove:\n",
        "                    new_edges.append([index_mapping[src], index_mapping[dst]])\n",
        "            if new_edges:\n",
        "                edge_index_new = torch.tensor(new_edges, dtype=torch.long).T\n",
        "            else:\n",
        "                edge_index_new = torch.empty((2, 0), dtype=torch.long)\n",
        "            compressed_data = Data(x=x_new, edge_index=edge_index_new)\n",
        "            return compressed_data, to_remove, alpha\n",
        "\n",
        "class GCNClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.fc = nn.Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return torch.sigmoid(self.fc(x)).view(-1)\n",
        "\n",
        "# ----------------------\n",
        "# Evaluation utility (same as training)\n",
        "# ----------------------\n",
        "def evaluate_with_hard_compression(compressor, classifier, loader, device):\n",
        "    classifier.eval()\n",
        "    compressor.eval()\n",
        "    y_true, y_pred, y_prob = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            compressed_data, removed, alpha = compressor.hard_compression_inference(batch.x, batch.edge_index)\n",
        "            compressed_data.y = batch.y.cpu()\n",
        "            compressed_data.batch = torch.zeros(compressed_data.x.size(0), dtype=torch.long)\n",
        "            compressed_data = compressed_data.to(device)\n",
        "\n",
        "            prob = classifier(compressed_data)  # length 1 tensor (batch_size=1)\n",
        "            pred = (prob >= 0.5).long()\n",
        "            y_true.append(int(batch.y.cpu().item()))\n",
        "            y_pred.append(int(pred.cpu().item()))\n",
        "            y_prob.append(float(prob.cpu().item()))\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_true, y_prob) if len(set(y_true)) > 1 else float('nan')\n",
        "    return {\"acc\":acc, \"prec\":prec, \"rec\":rec, \"f1\":f1, \"auc\":auc, \"y_true\": y_true, \"y_pred\": y_pred, \"y_prob\": y_prob}\n",
        "\n",
        "# ----------------------\n",
        "# Main evaluation flow\n",
        "# ----------------------\n",
        "if not os.path.isfile(save_path):\n",
        "    raise FileNotFoundError(f\"Checkpoint not found at {save_path}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger.info(f\"Using device: {device}\")\n",
        "\n",
        "# Read test protocol\n",
        "if not os.path.isfile(test_proto):\n",
        "    raise FileNotFoundError(f\"Test protocol not found at {test_proto}. Update proto_dir/test_proto paths.\")\n",
        "test_df = pd.read_csv(test_proto, sep=\" \", header=None)\n",
        "test_df.columns = [\"utt_id\", \"speaker_id\", \"system_id\", \"attack_id\", \"label\"]\n",
        "logger.info(f\"Test protocol contains {len(test_df)} rows\")\n",
        "\n",
        "# Build test graphs (this will read/flac files — can be slow)\n",
        "logger.info(\"Building test graphs (this may take a few minutes)...\")\n",
        "test_graphs = build_graph_list(test_df, eval_audio_dir, limit=None)\n",
        "if len(test_graphs) == 0:\n",
        "    raise RuntimeError(\"No test graphs were built — check eval_audio_dir and speaker_id->filename mapping\")\n",
        "logger.info(f\"Built {len(test_graphs)} test graphs\")\n",
        "\n",
        "test_loader = DataLoader(test_graphs, batch_size=1, shuffle=False)\n",
        "\n",
        "# Recreate models (must match training hyperparams)\n",
        "feature_dim = test_graphs[0].x.size(1)\n",
        "compressor = DifferentiableGraphCompressor(feature_dim, tau_T=1.0, lambda_id=1.0, lambda_comp=0.05).to(device)\n",
        "classifier = GCNClassifier(in_channels=feature_dim, hidden_channels=32).to(device)\n",
        "\n",
        "# Load checkpoint\n",
        "ckpt = torch.load(save_path, map_location=device)\n",
        "compressor.load_state_dict(ckpt['compressor_state'])\n",
        "classifier.load_state_dict(ckpt['classifier_state'])\n",
        "logger.info(f\"Loaded checkpoint from {save_path} (saved epoch={ckpt.get('epoch','?')}, dev_f1={ckpt.get('dev_f1','?')})\")\n",
        "\n",
        "# Evaluate\n",
        "metrics = evaluate_with_hard_compression(compressor, classifier, test_loader, device)\n",
        "logger.info(\"===== Test Results =====\")\n",
        "logger.info(f\"Accuracy : {metrics['acc']:.4f}\")\n",
        "logger.info(f\"Precision: {metrics['prec']:.4f}\")\n",
        "logger.info(f\"Recall   : {metrics['rec']:.4f}\")\n",
        "logger.info(f\"F1-score : {metrics['f1']:.4f}\")\n",
        "logger.info(f\"AUC      : {metrics['auc']}\")\n",
        "\n",
        "# Additional reports\n",
        "y_true = metrics['y_true']\n",
        "y_pred = metrics['y_pred']\n",
        "logger.info(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "logger.info(\"Classification report:\")\n",
        "print(classification_report(y_true, y_pred, digits=4, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PPaw5tzRhtjM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}